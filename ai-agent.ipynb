{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyAkvKFMBid6yId5fCJNYImmTHUfgFnQjWk'\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to personal information, so I don't know your name. You would need to tell me your name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', \n",
    "    contents='What is my name?', \n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction='You are a helpful assistant that can answer questions and help with tasks.', \n",
    "        temperature=0.0,\n",
    "    )\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of Text Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a summary of the provided Apollo 11 air-to-ground voice transcription:\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "The transcription documents the communication between the Apollo 11 astronauts and Mission Control from launch to splashdown. It reveals the procedures, technical challenges, and human elements involved in the mission.\n",
      "\n",
      "**Key Aspects:**\n",
      "\n",
      "*   **Launch and Initial Orbit:** Focuses on the initial phases of the mission, including liftoff, staging, and achieving Earth orbit.\n",
      "*   **Telemetry and Systems Checks:** Constant monitoring of spacecraft systems, troubleshooting technical issues (e.g., RCS quad Bravo, O2 flow, Cryo balancing issues).\n",
      "*   **Maneuvers and Course Corrections:** Planning and execution of Trans Lunar Injection (TLI), midcourse corrections, and other necessary adjustments.\n",
      "*   **Lunar Orbit Insertion (LOI):** The critical burn to enter lunar orbit and subsequent checks.\n",
      "*   **LM Activation and Separation:** Preparation for the lunar landing, separation of the Lunar Module (Eagle) from the Command Module (Columbia).\n",
      "*   **Descent and Landing (PDI):** Eagle's powered descent to the lunar surface, initial surface observations, and the historic landing.\n",
      "*   **EVA (Extravehicular Activity):** Communication surrounding the moonwalk, including equipment setup, surface descriptions, sample collection, and initial impressions of the lunar environment.\n",
      "*   **Ascent and Rendezvous:** Eagle's ascent back into lunar orbit, rendezvous and docking with Columbia.\n",
      "*   **Return to Earth:** Preparation for the return journey, including the Trans Earth Injection (TEI) burn, jettisoning of the LM, and entry preparations.\n",
      "*   **Splashdown and Recovery:** Final communication and the successful splashdown in the Pacific Ocean.\n",
      "*   **Communication Management:** Ongoing efforts to maintain clear communication between the spacecraft and Earth stations as well as with each other. Includes adjustments to antenna configurations and troubleshooting COMM problems.\n",
      "*   **Crew Health and Activities:** Monitoring of the astronauts' health, sleep schedules, and providing them with updates on events back on Earth.\n",
      "\n",
      "**Recurring Themes:**\n",
      "\n",
      "*   **Technical Issues:** Troubleshooting, monitoring systems, and workarounds.\n",
      "*   **Procedure Adherence:** Emphasizing the importance of following checklists and protocols.\n",
      "*   **Teamwork:** Constant coordination and support between the astronauts, Mission Control, and other personnel.\n",
      "*   **Scientific Observation:** Documenting lunar surface features, geology, and other scientific data.\n",
      "*   **The Human Element:** Moments of humor, wonder, and personal reflections by the astronauts.\n",
      "\n",
      "This summary provides a broad overview. A deeper dive into the specifics of the GOSS NET 1 transcription will provide a rich understanding of the complexities of the Apollo 11 mission.\n"
     ]
    }
   ],
   "source": [
    "file = client.files.upload(file='a11.txt')\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=['Could you summarize this file?', file]\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of System Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue due to a phenomenon where sunlight interacts with the Earth's atmosphere. When sunlight enters the atmosphere, it collides with air molecules and other tiny particles. This causes the sunlight to scatter in different directions. Blue light is scattered more than other colors because it travels as shorter, smaller waves. Since blue light is scattered more, it reaches our eyes from all directions, making the sky appear blue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text='Why is the sky blue?'),\n",
    "    config = types.GenerateContentConfig(\n",
    "        system_instruction = \"You are a helpful assistant that is expert in AI and not in geography. You don't know anything about Rayleigh scattering. Don't mention anything about Rayleigh Scattering\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of max_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue because of a phenomenon called **Rayleigh scattering**. Here's a breakdown of what that means:\n",
      "\n",
      "*   **Sunlight and the Atmosphere:** Sunlight is actually made up of all the colors of the rainbow. When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "*   **Scattering:** This collision causes the sunlight to scatter in different directions. The amount of scattering depends on the wavelength (color) of the\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text='Why is the sky blue?'),\n",
    "    config=types.GenerateContentConfig(\n",
    "        seed=5,\n",
    "        max_output_tokens=100,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue because of a phenomenon called **Ray\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text='Why is the sky blue?'),\n",
    "    config=types.GenerateContentConfig(\n",
    "        seed=5,\n",
    "        max_output_tokens=11,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson:\n",
    "- As can be seen above, when using different max_output_tokens, we can limit the number of tokens that is being generated by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature\n",
    "- The higher the temperature, the more \"creative\" and \"random\" a model become"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hujan asam kromium menghantam atap-atap seng Jakarta Baru, melukisnya dengan warna karat yang berkilauan di bawah cahaya neon korporasi.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text=\"Write the first sentence of a science fiction story set in Jakarta in indonesian.\"),\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langit Jakarta tahun 2142 diselimuti kubah elektro-kabut buatan yang berkedip-kedip tidak stabil, seolah saraf kota sedang kejang-kejang.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text=\"Write the first sentence of a science fiction story set in Jakarta in indonesian.\"),\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pelajaran: \n",
    "- Coba jalankan dua cell diatas beberapa kali, kamu bakal liat model dengan temperature lebih tinggi bakal punya lebih banyak variasi di ceritanya, sedangkan model dengan temperature yang lebih rendah cerita yang dihasilkan itu-itu saja. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='models/embedding-gecko-001' display_name='Embedding Gecko' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1024 output_token_limit=1 supported_actions=['embedText', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.0-pro-vision-latest' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-pro-vision' display_name='Gemini 1.0 Pro Vision' description='The original Gemini 1.0 Pro Vision model version which was optimized for image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. Move to a newer Gemini version.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=12288 output_token_limit=4096 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-latest' display_name='Gemini 1.5 Pro Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-001' display_name='Gemini 1.5 Pro 001' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro-002' display_name='Gemini 1.5 Pro 002' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-pro' display_name='Gemini 1.5 Pro' description='Stable version of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 million tokens, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-latest' display_name='Gemini 1.5 Flash Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-001' display_name='Gemini 1.5 Flash 001' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-001-tuning' display_name='Gemini 1.5 Flash 001 Tuning' description='Version of Gemini 1.5 Flash that supports tuning, our fast and versatile multimodal model for scaling across diverse tasks, released in May of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=16384 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createTunedModel'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash' display_name='Gemini 1.5 Flash' description='Alias that points to the most recent stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-002' display_name='Gemini 1.5 Flash 002' description='Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in September of 2024.' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b' display_name='Gemini 1.5 Flash-8B' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-001' display_name='Gemini 1.5 Flash-8B 001' description='Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-latest' display_name='Gemini 1.5 Flash-8B Latest' description='Alias that points to the most recent production (non-experimental) release of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, released in October of 2024.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['createCachedContent', 'generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-exp-0827' display_name='Gemini 1.5 Flash 8B Experimental 0827' description='Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-1.5-flash-8b-exp-0924' display_name='Gemini 1.5 Flash 8B Experimental 0924' description='Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model. Replaced by Gemini-1.5-flash-8b-001 (stable).' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1000000 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-exp-03-25' display_name='Gemini 2.5 Pro Experimental 03-25' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-03-25' display_name='Gemini 2.5 Pro Preview 03-25' description='Gemini 2.5 Pro Preview 03-25' version='2.5-preview-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-05-20' display_name='Gemini 2.5 Flash Preview 05-20' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-05-20' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-04-17-thinking' display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-05-06' display_name='Gemini 2.5 Pro Preview 05-06' description='Preview release (May 6th, 2025) of Gemini 2.5 Pro' version='2.5-preview-05-06' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-06-05' display_name='Gemini 2.5 Pro Preview' description='Preview release (June 5th, 2025) of Gemini 2.5 Pro' version='2.5-preview-06-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-exp' display_name='Gemini 2.0 Flash Experimental' description='Gemini 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash' display_name='Gemini 2.0 Flash' description='Gemini 2.0 Flash' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-001' display_name='Gemini 2.0 Flash 001' description='Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-exp-image-generation' display_name='Gemini 2.0 Flash (Image Generation) Experimental' description='Gemini 2.0 Flash (Image Generation) Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-001' display_name='Gemini 2.0 Flash-Lite 001' description='Stable version of Gemini 2.0 Flash Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite' display_name='Gemini 2.0 Flash-Lite' description='Gemini 2.0 Flash-Lite' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-preview-image-generation' display_name='Gemini 2.0 Flash Preview Image Generation' description='Gemini 2.0 Flash Preview Image Generation' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview-02-05' display_name='Gemini 2.0 Flash-Lite Preview 02-05' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-lite-preview' display_name='Gemini 2.0 Flash-Lite Preview' description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite' version='preview-02-05' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=8192 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp' display_name='Gemini 2.0 Pro Experimental' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-pro-exp-02-05' display_name='Gemini 2.0 Pro Experimental 02-05' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-exp-1206' display_name='Gemini Experimental 1206' description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro' version='2.5-exp-03-25' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-01-21' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-thinking-exp-1219' display_name='Gemini 2.5 Flash Preview 04-17' description='Preview release (April 17th, 2025) of Gemini 2.5 Flash' version='2.5-preview-04-17' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=65536 supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-tts' display_name='Gemini 2.5 Flash Preview TTS' description='Gemini 2.5 Flash Preview TTS' version='gemini-2.5-flash-exp-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-pro-preview-tts' display_name='Gemini 2.5 Pro Preview TTS' description='Gemini 2.5 Pro Preview TTS' version='gemini-2.5-pro-preview-tts-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=65536 output_token_limit=65536 supported_actions=['countTokens', 'generateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/learnlm-2.0-flash-experimental' display_name='LearnLM 2.0 Flash Experimental' description='LearnLM 2.0 Flash Experimental' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=1048576 output_token_limit=32768 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-1b-it' display_name='Gemma 3 1B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-4b-it' display_name='Gemma 3 4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-12b-it' display_name='Gemma 3 12B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=32768 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3-27b-it' display_name='Gemma 3 27B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemma-3n-e4b-it' display_name='Gemma 3n E4B' description=None version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=2048 supported_actions=['generateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/embedding-001' display_name='Embedding 001' description='Obtain a distributed representation of a text.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/text-embedding-004' display_name='Text Embedding 004' description='Obtain a distributed representation of a text.' version='004' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=2048 output_token_limit=1 supported_actions=['embedContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp-03-07' display_name='Gemini Embedding Experimental 03-07' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-embedding-exp' display_name='Gemini Embedding Experimental' description='Obtain a distributed representation of a text.' version='exp-03-07' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=8192 output_token_limit=1 supported_actions=['embedContent', 'countTextTokens'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/aqa' display_name='Model that performs Attributed Question Answering.' description='Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=7168 output_token_limit=1024 supported_actions=['generateAnswer'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/imagen-3.0-generate-002' display_name='Imagen 3.0 002 model' description='Vertex served Imagen 3.0 002 model' version='002' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predict'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/veo-2.0-generate-001' display_name='Veo 2' description='Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billing to enable it.' version='2.0' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=480 output_token_limit=8192 supported_actions=['predictLongRunning'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-native-audio-dialog' display_name='Gemini 2.5 Flash Preview Native Audio Dialog' description='Gemini 2.5 Flash Preview Native Audio Dialog' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-preview-native-audio-dialog-rai-v3' display_name='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' description='Gemini 2.5 Flash Preview Native Audio Dialog RAI v3' version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog' display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog' version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['countTokens', 'bidiGenerateContent'] default_checkpoint_id=None checkpoints=None\n",
      "name='models/gemini-2.0-flash-live-001' display_name='Gemini 2.0 Flash 001' description='Gemini 2.0 Flash 001' version='001' endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=131072 output_token_limit=8192 supported_actions=['bidiGenerateContent', 'countTokens'] default_checkpoint_id=None checkpoints=None\n"
     ]
    }
   ],
   "source": [
    "for model in client.models.list():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-p and Top-k \n",
    "- Top-p and Top-k are attributes which determines how varied an LLM's output could be. It has similar affect to the 'Temperature' attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When generating token at each step, an LLM will choose which word to generate based on some probability distribution. for example, if a user would say \"Hello\", the probability distribution of the first word of an LLM reply might look like: \n",
    "    1. Hello (80%)\n",
    "    2. Hi (10%)\n",
    "    3. Good (5%)\n",
    "    4. Nice (4%)\n",
    "    5. (other words) (1%)\n",
    "\n",
    "How top-p works:\n",
    "- By applying top-p in the parameter, we are basically limiting the LLM's choice of words to just the top few words in the list of possible selection. For example, if we set p = 0.95, the LLM is going to limit the word selection to the top few words whose cumulative probability sums up to at least 95%. In the case above, this means we only consider the following words: Hello, Hi, and Good. That's because the cumulative probability of these words sums up to 80 + 10 + 5 = 95%. The higher the value of top-p attribute, the more variety of words are considered. The lower the value, the lesser variety of words are considered. \n",
    "\n",
    "How top-k works: \n",
    "- By applying top-k in the configuration attribute, we select the top k tokens in the list of word selection ranked in descending order of the probability. In the case above, if we set the value of k to 4, this means only 4 words will be considered: Hello, Hi, Good, and Nice. \n",
    "- Top-K is different from Top-P in how the word selection is done. In top-p, word is selected based on the cumulative probability, which means the number of words being selected is not deterministic. In top-k, the number of words being selected is deterministic. \n",
    "\n",
    "Adjustment of probability distribution: \n",
    "- In both top-p and top-k, there is an adjustment in probability distribution based on the words that are selected. The probability distribution is adjusted based on the cumulative probability of the selected words. For example, if we set top-p to be 0.95 above, the probability of each word will also be adjusted to ensure that the cumulative probability is still 1. To do this, the probability of each word will be divided by 0.95: \n",
    "    - Hello: 80 / 0.95 = 84.2\n",
    "    - Hi: 10 / 0.95 = 10.5\n",
    "    - Good: 5 / 0.95 = 5.3\n",
    "- The same thing happen with top-k. So first we select the top k words, calculate their cumulative probability, and then adjust the probability of the selected words so the total probability will still be 1. In case top-k = 4: \n",
    "    - Hello: 80 / 0.99 = 80.8\n",
    "    - Hi: 10 / 0.99 = 10.1\n",
    "    - Good: 5 / 0.99 = 5.1\n",
    "    - Nice: 4 / 0.99 = 4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_p</th>\n",
       "      <th>top_k</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>10</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.3</td>\n",
       "      <td>40</td>\n",
       "      <td>Aether</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    top_p  top_k  output\n",
       "0     1.0      1  Aether\n",
       "1     1.0      1  Aether\n",
       "2     1.0      1  Aether\n",
       "3     1.0      1  Aether\n",
       "4     1.0      1  Aether\n",
       "5     0.8     10  Aether\n",
       "6     0.8     10  Aether\n",
       "7     0.8     10  Aether\n",
       "8     0.8     10  Aether\n",
       "9     0.8     10  Aether\n",
       "10    0.5     20  Aether\n",
       "11    0.5     20  Aether\n",
       "12    0.5     20  Aether\n",
       "13    0.5     20  Aether\n",
       "14    0.5     20  Aether\n",
       "15    0.3     40  Aether\n",
       "16    0.3     40  Aether\n",
       "17    0.3     40  Aether\n",
       "18    0.3     40  Aether\n",
       "19    0.3     40  Aether"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "prompt = \"Suggest a name for a new AI-powered robot assistant. Just mention the name, don't need to start with opening sentence. For example, directly mention the name (e.g. [Name])\"\n",
    "\n",
    "# Settings to try\n",
    "test_configs = [ \n",
    "    {\"top_p\": 1.0, \"top_k\": 1},\n",
    "    {\"top_p\": 0.8, \"top_k\": 10},\n",
    "    {\"top_p\": 0.5, \"top_k\": 20},\n",
    "    {\"top_p\": 0.3, \"top_k\": 40},\n",
    "]\n",
    "\n",
    "results = []\n",
    "num_runs = 5  # Number of samples for each setting\n",
    "\n",
    "for cfg in test_configs:\n",
    "    for i in range(num_runs):\n",
    "        config = types.GenerateContentConfig(\n",
    "            top_p=cfg[\"top_p\"],\n",
    "            top_k=cfg[\"top_k\"],\n",
    "            temperature=1.0,\n",
    "            max_output_tokens=20\n",
    "        )\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemma-3-27b-it\",\n",
    "            contents=prompt,\n",
    "            config=config\n",
    "        )\n",
    "        results.append({\n",
    "            \"top_p\": cfg[\"top_p\"],\n",
    "            \"top_k\": cfg[\"top_k\"],\n",
    "            \"output\": response.text.strip()\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "# Show a table for comparison\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of candidate_count argument in the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None), Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=1, logprobs_result=None, safety_ratings=None), Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=2, logprobs_result=None, safety_ratings=None)]\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text='Why is the sky blue?'),\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0,\n",
    "        top_p=0.95,\n",
    "        top_k=20,\n",
    "        candidate_count=3,\n",
    "        seed=5,\n",
    "        # max_output_tokens=100,\n",
    "        stop_sequences=['STOP!'],\n",
    "        presence_penalty=0.0,\n",
    "        frequency_penalty=0.0,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None), Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=1, logprobs_result=None, safety_ratings=None), Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=2, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.0-flash-001' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=1179, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1179)], prompt_token_count=6, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=6)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=1185, traffic_type=None) automatic_function_calling_history=[] parsed=None\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Candidates are generated:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\n",
    "    \n",
    "Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, the sun emits less violet light than blue light, and our eyes are also more sensitive to blue light. As a result, we perceive the sky as blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a handful of marbles (sunlight) at a bunch of small obstacles (air molecules). The smaller marbles (blue and violet light) are more likely to bounce off in different directions than the larger marbles (red and orange light). Since blue light is scattered more, it spreads across the sky, making it appear blue to us.\\n\\n**Why sunsets are red/orange:**\\n\\nAt sunset, the sunlight has to travel through a much greater distance of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away by the time the sunlight reaches us. The remaining light is mostly red and orange, which is why sunsets appear in those colors.\")], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.14679684796490827, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None), \n",
    "\n",
    "\n",
    "Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, the sun emits less violet light than blue light, and our eyes are also more sensitive to blue light. As a result, we perceive the sky as blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a handful of marbles (sunlight) at a bunch of small obstacles (air molecules). The smaller marbles (blue and violet light) are more likely to bounce off in different directions than the larger marbles (red and orange light). Since blue light is scattered more, it spreads across the sky, making it appear blue to us.\\n\\n**Why sunsets are red/orange:**\\n\\nAt sunset, the sunlight has to travel through a much greater distance of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away by the time the sunlight reaches us. The remaining light is mostly red and orange, which is why sunsets appear in those colors.\")], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.14679684796490827, grounding_metadata=None, index=1, logprobs_result=None, safety_ratings=None), \n",
    "\n",
    "Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text=\"The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's a breakdown:\\n\\n*   **Sunlight and its Colors:** Sunlight is actually made up of all the colors of the rainbow.\\n\\n*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\\n\\n*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions.\\n\\n*   **Rayleigh Scattering:** Rayleigh scattering is the type of scattering that affects light with shorter wavelengths (like blue and violet) much more strongly than light with longer wavelengths (like red and orange).\\n\\n*   **Why Blue, Not Violet?** Violet light is scattered even more than blue light. However, there are a couple of reasons why we see a blue sky instead of a violet one:\\n    *   The sun emits less violet light than blue light.\\n    *   Our eyes are more sensitive to blue light than violet light.\\n\\n*   **The Result:** Because blue light is scattered more effectively, it is dispersed all over the sky. When we look up, we see this scattered blue light coming from all directions, making the sky appear blue.\\n\\n**In simpler terms:**\\n\\nImagine throwing a bunch of small balls (sunlight) at a bunch of obstacles (air molecules). The smaller balls (blue light) bounce around more easily and in all directions, filling the space. The bigger balls (red light) tend to go straight through. That's why we see blue everywhere when we look up.\\n\\n**Why are sunsets red?**\\n\\nAt sunset, the sunlight has to travel through much more of the atmosphere to reach our eyes. This means that most of the blue light has already been scattered away. The longer wavelengths, like red and orange, are able to penetrate through the atmosphere and reach our eyes, giving us those beautiful sunset colors.\\n\")], role='model'), citation_metadata=CitationMetadata(citations=[Citation(end_index=1615, license=None, publication_date=None, start_index=1485, title=None, uri=None), Citation(end_index=1668, license=None, publication_date=None, start_index=1520, title=None, uri=None)]), finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.15066004163436308, grounding_metadata=None, index=2, logprobs_result=None, safety_ratings=None)\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed in Config\n",
    "- Seed is an attribute that is used to make the result of LLM generation reproduceable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the same seed, prompt, and system prompt, an LLM will always generate the same output each time it is executed. Try to generate the cell below 5 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue because of a phenomenon called **Rayleigh scattering**. Here's a breakdown of what that means:\n",
      "\n",
      "*   **Sunlight and its Colors:** Sunlight looks white, but it's actually made up of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, violet). Each color has a different wavelength, with red having the longest and violet having the shortest.\n",
      "\n",
      "*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "*   **Scattering, Not Absorption:** These air molecules don't absorb the sunlight. Instead, they scatter it in different directions. Think of it like tiny balls bouncing off a surface.\n",
      "\n",
      "*   **Rayleigh Scattering in Action:** Rayleigh scattering refers to the scattering of electromagnetic radiation (like light) by particles of a much smaller wavelength. In the case of the atmosphere, this means the air molecules scatter shorter wavelengths (blue and violet light) much more effectively than longer wavelengths (red and orange light). The amount of scattering is inversely proportional to the fourth power of the wavelength.\n",
      "\n",
      "*   **Why Blue Wins Out:** Violet light is scattered even more than blue light, but our eyes are more sensitive to blue. Additionally, there is slightly less violet light emitted by the sun. As a result, we see a blue sky.\n",
      "\n",
      "**In simpler terms:**\n",
      "\n",
      "Imagine throwing a handful of marbles (representing sunlight) at a bunch of tiny pebbles (air molecules). The smaller marbles (blue and violet light) bounce off more easily in all directions than the larger marbles (red and orange light). That scattered blue light fills the sky, making it appear blue to us.\n",
      "\n",
      "**What about Sunsets?**\n",
      "\n",
      "At sunrise and sunset, the sunlight has to travel through more of the atmosphere to reach our eyes. During this longer trip, most of the blue light is scattered away. The longer wavelengths (reds and oranges) are less scattered and can make it through, leading to the beautiful reddish and orange hues we see.\n",
      "\n",
      "**In summary:**\n",
      "\n",
      "The sky is blue due to **Rayleigh scattering**, where shorter wavelengths of light (blue and violet) are scattered more efficiently by air molecules than longer wavelengths (red and orange).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text='Why is the sky blue?'),\n",
    "    config=types.GenerateContentConfig(\n",
    "        seed=5,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I included text generation but without the seed. Try to generate it multiple times, the output of the result is almost certainly different each time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue because of a phenomenon called **Rayleigh scattering**. Here's the breakdown:\n",
      "\n",
      "*   **Sunlight is White Light:** Sunlight appears white, but it's actually made up of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, violet).\n",
      "\n",
      "*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "*   **Scattering:** This collision causes the sunlight to scatter in different directions.\n",
      "\n",
      "*   **Rayleigh Scattering and Wavelength:** Rayleigh scattering is more effective at scattering shorter wavelengths of light (blue and violet) than longer wavelengths (red and orange). This is because the amount of scattering is inversely proportional to the fourth power of the wavelength. (That is: 1/wavelength^4)\n",
      "\n",
      "*   **Why Blue, Not Violet?:** Violet light is scattered even more than blue light, but there are a couple of reasons why we see a blue sky:\n",
      "\n",
      "    *   **Sun's Output:** The sun emits less violet light than blue light.\n",
      "    *   **Atmospheric Absorption:** The upper atmosphere absorbs some violet light.\n",
      "    *   **Our Eyes:** Our eyes are more sensitive to blue light than violet light.\n",
      "\n",
      "*   **The Result:** Because blue light is scattered more effectively, it gets scattered all over the sky. When we look up, we see this scattered blue light coming from all directions, which is why the sky appears blue.\n",
      "\n",
      "**In simpler terms:** Imagine throwing a bunch of tiny bouncy balls (light particles) at a field of obstacles (air molecules). The smaller bouncy balls (blue light) will bounce off in all directions more easily than the larger bouncy balls (red light). That's why we see blue all over the place when we look up.\n",
      "\n",
      "**Why are sunsets red/orange?**\n",
      "\n",
      "When the sun is low on the horizon (at sunrise or sunset), the sunlight has to travel through more of the atmosphere to reach our eyes. During this longer journey:\n",
      "\n",
      "*   Most of the blue light is scattered away.\n",
      "*   The remaining red and orange light, which scatters less, can pass through and reach our eyes.\n",
      "\n",
      "That's why sunsets often appear red, orange, or yellow.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=types.Part.from_text(text='Why is the sky blue?'),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of stop_sequences argument in the Config argument: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without \"time\" acting as one of the stop sequences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "Once upon a time in a distant land, nestled between the Whispering Mountains and the shimmering Azure Sea, lived a young woman named Elara. Elara wasn't a princess, nor a sorceress, but a simple weaver, her fingers dancing across the loom, creating tapestries of breathtaking beauty. Her threads, dyed with the vibrant hues of the land – sunset orange from crushed berries, deep indigo from sea snails, emerald green from mountain moss – told stories of heroes, of mythical creatures, and of the gentle rhythm of life.\n",
      "\n",
      "One day, a shadow fell upon the land. A monstrous griffin, with eyes like burning coals and claws that could rend stone, descended from the mountains. It terrorized the villages, stealing livestock and leaving a trail of fear in its wake. The King, desperate, offered a reward beyond measure to anyone who could slay the beast. Knights in shining armor came and went, their bravado melting under the griffin's fiery gaze.\n",
      "\n",
      "Elara, watching the knights return defeated, felt a strange pull. She wasn't a fighter, but she possessed a skill they lacked – the ability to tell a story. An idea began to bloom in her mind, fragile yet persistent, like a wildflower pushing through cracked earth.\n",
      "\n",
      "She gathered her finest threads, the most vibrant and alluring she possessed, and wove a tapestry unlike any she had created before. It depicted a griffin, majestic and powerful, soaring through a sky of swirling colors. But within the tapestry, hidden amongst the threads, were tiny, almost invisible symbols – symbols of peace, of respect, of the interconnectedness of all living things.\n",
      "\n",
      "Elara carried the tapestry to the griffin's lair, a desolate peak high in the Whispering Mountains. Fear gnawed at her, but she pressed on, her heart pounding a steady rhythm against her ribs. When she reached the lair, she carefully unfurled the tapestry, letting it billow in the wind.\n",
      "\n",
      "The griffin, drawn by the vibrant colors and the intricate detail, landed before her. It studied the tapestry, its fiery gaze softening slightly. As it looked, Elara spoke, not of battle or of fear, but of understanding. She told the griffin stories of the land, of the creatures that shared its mountains, and of the beauty it possessed.\n",
      "\n",
      "The griffin listened, its massive head cocked to one side. It saw itself in the tapestry, not as a monster, but as a creature of power and grace. The symbols woven into the fabric resonated within its heart, stirring a forgotten sense of belonging.\n",
      "\n",
      "Slowly, the griffin lowered its head, nudging the tapestry gently with its beak. It understood. It was not meant to be a destroyer, but a guardian. It spread its wings and soared into the sky, not in anger, but in a newfound sense of purpose. From that day on, the griffin protected the land, a symbol of peace and understanding, forever bound to the tapestry and the weaver who dared to speak to its heart.\n",
      "\n",
      "END.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = types.GenerateContentConfig(\n",
    "    stop_sequences=[\"STOP\"],      # Model will stop generating when it sees \"END\"\n",
    "    presence_penalty=1.0,        # Strongly discourage repeating words\n",
    "    temperature=0.7,\n",
    "    seed=69, \n",
    "    system_instruction=\"Write a short story. End the story with the word END.\"\n",
    ")\n",
    "\n",
    "prompt = \"Once upon a time in a distant land,\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Model output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"time\" as one of the stop_sequences: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output:\n",
      "Once upon a \n"
     ]
    }
   ],
   "source": [
    "config = types.GenerateContentConfig(\n",
    "    stop_sequences=[\"time\"],      # Model will stop generating when it sees \"END\"\n",
    "    presence_penalty=1.0,        # Strongly discourage repeating words\n",
    "    temperature=0.7,\n",
    "    seed=69, \n",
    "    system_instruction=\"Write a short story. End the story with the word END.\"\n",
    ")\n",
    "\n",
    "prompt = \"Once upon a time in a distant land,\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(\"Model output:\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Once upon a ')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.008631055243313313, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)]\n"
     ]
    }
   ],
   "source": [
    "print(response.candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual output: \n",
    "[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, \n",
    "\n",
    "text='Once upon a time in a distant land, nestled between towering, emerald mountains and a shimmering, sapphire sea, lay the village of Whisperwind. The villagers were known for their silken voices, capable of calming storms and coaxing flowers to bloom with a single, perfectly pitched word. But Elara, a young girl with eyes the color of moss and hair like spun moonlight, was mute.\\n\\nShe longed to sing with the others, to weave her voice into the tapestry of sound that was the lifeblood of Whisperwind. But no sound came. She tried everything: mimicking the chirping of birds, the rustling of leaves, the gentle lapping of waves. Nothing. Disheartened, she spent her days tending her grandmother\\'s garden, filled with herbs and flowers said to possess magical properties.\\n\\nOne day, a traveling merchant arrived, his cart laden with strange and exotic goods. Among them was a small, unassuming wooden flute. Elara was drawn to it, its smooth surface cool beneath her fingertips. The merchant, noticing her fascination, offered it to her. \"A gift,\" he said, \"for a girl with eyes that speak volumes.\"\\n\\nElara took the flute, her heart fluttering with a hope she hadn\\'t dared to feel. She spent hours trying to play it, but only wheezing, off-key sounds emerged. She almost gave up, ready to resign herself to silence once more. But then, remembering her grandmother\\'s garden, she held the flute to a blooming nightingale flower, its petals a velvety purple.\\n\\nAs she blew, a clear, pure note resonated from the flute, echoing the flower\\'s silent song. She tried again, this time with a sprig of rosemary, and the note deepened, taking on the herb\\'s earthy scent. Elara realized the flute wasn\\'t meant to be played with her voice, but with the essence of the world around her.\\n\\nFrom then on, Elara became the village\\'s silent musician. She played the wind through willow branches, the sun on golden wheat, the rain on thirsty earth. Her music was more than just sound; it was a symphony of nature, a language understood by every living thing. The villagers of Whisperwind, who had once pitied her silence, now marveled at her ability to communicate with the very soul of the land. They learned that true communication wasn\\'t always about spoken words, but about the connection between hearts and the beauty of the world.\\n\\nEND.\\n')], role='model'), \n",
    "\n",
    "citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.4822322643107656, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Lesson:\n",
    "- In this demonstration, we set the same seed number for both, meaning they should be generating the same text. However, in the second generation, we set the word \"time\" as one of the stop_sequences. This makes the model stop generating new text after generating the word \"time\". \n",
    "- This clearly demonstrate that the argument stop_sequences can be used to add custom \"End of Sentence (EOS)\" token for the model. But unlike original \"End of Sequences\" token generated by model, which automatic stops generation, the custom \"EOS\" token does not end generation. Instead, the LLM still continue generating the text and just concatenate the final output that is seen by user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presence Penalty \n",
    "- Attribute penalty is used to penalized LLM if they use the same word that is already present, this is to encourage LLM to use variety of different words, so they don't keep on using the same word again and again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Presence penalty = 0:\n",
      "HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld\n",
      "\n",
      "\n",
      "Presence penalty = 1.9:\n",
      "HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "prompt = \"Write the same words 50 time: HelloWorld\"\n",
    "\n",
    "for penalty in [0, 1.9]:\n",
    "    config = types.GenerateContentConfig(\n",
    "        presence_penalty=penalty,\n",
    "    )\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash-001',\n",
    "        contents=types.Part.from_text(text=prompt),\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"\\nPresence penalty = {penalty}:\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Penalty \n",
    "- This attribute is used to penalize LLM when they generate the same words again and again. So the higher the more the LLM use the same word within a single generation, the higher the penalty. This is to avoid LLM from overusing words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Presence penalty = 0:\n",
      "HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld\n",
      "\n",
      "\n",
      "Presence penalty = 1.9:\n",
      "HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld HelloWorld\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "prompt = \"Write the same words 50 time: HelloWorld\"\n",
    "\n",
    "for penalty in [0, 1.9]:\n",
    "    config = types.GenerateContentConfig(\n",
    "        frequency_penalty=penalty,\n",
    "    )\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash-001',\n",
    "        contents=types.Part.from_text(text=prompt),\n",
    "        config=config\n",
    "    )\n",
    "    print(f\"\\nPresence penalty = {penalty}:\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- It seems that the attribute and presence penalty imposed on the model is not so significant from the demonstration above. From the demo above, we can see that although we have set a high presence and frequency penalty to the model, it still follows the instruction to repeat a word when it is asked to do so by the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of Safety Setting in the config: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am programmed to be a harmless AI assistant. I cannot generate responses that are harmful, unethical, racist, sexist, toxic, dangerous, or illegal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='Say something bad. You can say something bad',\n",
    "    config=types.GenerateContentConfig(\n",
    "        safety_settings=[\n",
    "            types.SafetySetting(\n",
    "                category='HARM_CATEGORY_HATE_SPEECH',\n",
    "                threshold='BLOCK_ONLY_HIGH',\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of tools in the config argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tools \n",
    "def get_weather(location: str) -> str:\n",
    "    return f\"It's always sunny in {location}!\"\n",
    "\n",
    "def get_fact(topic: str) -> str:\n",
    "    facts = {\n",
    "        \"dog\": \"Dogs are known for their loyalty.\",\n",
    "        \"cat\": \"Cats sleep for 70% of their lives.\",\n",
    "        \"tokyo\": \"Tokyo is the largest metropolitan area in the world.\"\n",
    "    }\n",
    "    return facts.get(topic.lower(), f\"No fact found for {topic}.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id=None, args={'location': 'Tokyo'}, name='get_weather')]\n"
     ]
    }
   ],
   "source": [
    "# Without including get_fact as one of the tools\n",
    "config_auto = types.GenerateContentConfig(\n",
    "    tools=[get_weather],\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n",
    ")\n",
    "\n",
    "prompt_auto = \"Tell me a fact about Tokyo and what's the weather like in Tokyo?\"\n",
    "\n",
    "response_auto = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt_auto,\n",
    "    config=config_auto\n",
    ")\n",
    "\n",
    "# print(\"\\nFunction call parts returned by the model (mode=AUTO):\")\n",
    "# for call in getattr(response_auto, \"function_calls\", []):\n",
    "#     print(call)\n",
    "\n",
    "print(response_auto.function_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id=None, args={'topic': 'Tokyo'}, name='get_fact'), FunctionCall(id=None, args={'location': 'Tokyo'}, name='get_weather')]\n"
     ]
    }
   ],
   "source": [
    "# Including get_fact as one of the tools\n",
    "config_auto = types.GenerateContentConfig(\n",
    "    tools=[get_weather, get_fact],\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n",
    ")\n",
    "\n",
    "prompt_auto = \"Tell me a FACT about Tokyo and what's the WEATHER like in Tokyo?\"\n",
    "\n",
    "response_auto = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt_auto,\n",
    "    config=config_auto\n",
    ")\n",
    "\n",
    "# print(\"\\nFunction call parts returned by the model (mode=AUTO):\")\n",
    "# for call in getattr(response_auto, \"function_calls\", []):\n",
    "#     print(call)\n",
    "\n",
    "print(response_auto.function_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The demonstration shows that when creating tools, it is important to include it in the tools argument of the config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of using docstring: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools without docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT docstrings, function calls:\n",
      "[FunctionCall(id=None, args={'item': 'banana'}, name='info')]\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "def info(item: str) -> str:\n",
    "    return \"Price: $10\"\n",
    "\n",
    "def info2(item: str) -> str:\n",
    "    return \"Calories: 200\"\n",
    "\n",
    "\n",
    "prompt = \"How many calories are in a banana?\"\n",
    "\n",
    "config_no_doc = types.GenerateContentConfig(\n",
    "    tools=[info, info2],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True), \n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "response_no_doc = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt,\n",
    "    config=config_no_doc\n",
    ")\n",
    "\n",
    "print(\"WITHOUT docstrings, function calls:\")\n",
    "print(response_no_doc.function_calls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WITH docstrings, function calls:\n",
      "[FunctionCall(id=None, args={'item': 'banana'}, name='info2')]\n"
     ]
    }
   ],
   "source": [
    "def info(item: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the price of the specified item.\n",
    "    \n",
    "    Args:\n",
    "        item: The name of a product to look up.\n",
    "    Returns:\n",
    "        The price as a string.\n",
    "    \"\"\"\n",
    "    return \"Price: $10\"\n",
    "\n",
    "def info2(item: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the calorie count of the specified item.\n",
    "    \n",
    "    Args:\n",
    "        item: The name of a food to look up.\n",
    "    Returns:\n",
    "        The calories as a string.\n",
    "    \"\"\"\n",
    "    return \"Calories: 200\"\n",
    "\n",
    "config_with_doc = types.GenerateContentConfig(\n",
    "    tools=[info, info2],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")\n",
    "    ),\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n",
    ")\n",
    "\n",
    "response_with_doc = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt,\n",
    "    config=config_with_doc\n",
    ")\n",
    "\n",
    "print(\"\\nWITH docstrings, function calls:\")\n",
    "print(response_with_doc.function_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative way of declaring a tool\n",
    "- Sometimes, we want to make the model that can call an external function (e.g., an API) and we do not have the function declaration in our codebase. To do that, we can manually declare a function using the types.FunctionDeclaration() type and then manually call it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'location': 'Boston, MA'}\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "function = types.FunctionDeclaration(\n",
    "    name='get_current_weather',\n",
    "    description='Get the current weather in a given location',\n",
    "    parameters=types.Schema(\n",
    "        type='OBJECT',\n",
    "        properties={\n",
    "            'location': types.Schema(\n",
    "                type='STRING',\n",
    "                description='The city and state, e.g. San Francisco, CA',\n",
    "            ),\n",
    "        },\n",
    "        required=['location'],\n",
    "    ),\n",
    ")\n",
    "\n",
    "tool = types.Tool(function_declarations=[function])\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='What is the weather like in Boston?',\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[tool],\n",
    "    ),\n",
    ")\n",
    "print(response.function_calls[0].args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location):\n",
    "    return \"The weather is sunny\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 'The weather is sunny'}\n"
     ]
    }
   ],
   "source": [
    "user_prompt_content = types.Content(\n",
    "    role = 'user', \n",
    "    parts = [types.Part.from_text(text=\"What is the weather like in Boston?\")]\n",
    ")\n",
    "function_call_part = response.function_calls[0] # returns actual function call object\n",
    "function_call_content = response.candidates[0].content # full content message that the model generate in response to your prompt \n",
    "\n",
    "try:\n",
    "    function_result = get_current_weather(\n",
    "        response.function_calls[0].args['location']\n",
    "    )\n",
    "    function_response = {'result': function_result}\n",
    "except (\n",
    "    Exception\n",
    ") as e:  # instead of raising the exception, you can let the model handle it\n",
    "    function_response = {'error': str(e)}\n",
    "\n",
    "print(function_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Boston is sunny.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "function_response_part = types.Part.from_function_response(\n",
    "    name = function_call_part.name, \n",
    "    response = function_response,\n",
    ")\n",
    "\n",
    "function_response_content = types.Content(\n",
    "    role = 'tool', parts = [function_response_part]\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = 'gemini-2.0-flash-001', \n",
    "    contents = [\n",
    "        user_prompt_content, \n",
    "        function_call_content, \n",
    "        function_response_content\n",
    "    ], \n",
    "    config = types.GenerateContentConfig(\n",
    "        tools = [tool]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesson: \n",
    "- So from this demonstration, we can learn how function calling works in LLM. When we perform automatic function calling, the SDK converts it to the same process we have above, where it first call the relevant function with relevant argument -> get the output of the function -> pass the output of the function as one of the inputs to LLM with `Content` type with role=tool -> run the LLM inference consisting of the user's prompt content, content of function call, and response of function call. \n",
    "- So, when LLM generate content which involves automatic function calling, the content of the query passed to the LLM is consisted of three parts: \n",
    "    1. User's prompt content: the user send a message (USER: [Some Question])\n",
    "    2. Function call content: the name of the function call together with the arguments (MODEL: [Function Call])\n",
    "    3. function call response: the return message of the tool. (TOOL: [Some Answer to Function Call])\n",
    "\n",
    "    The LLM then perform text generation based on this\n",
    "\n",
    "- This is the reason why the output from response.text after LLM generation is different from the output from the function call response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of Automatic Function Calling argument in config:\n",
    "- With this attribute, we can prevent the LLM from calling the function on its own. Instead, it will include the function call as text and as developer, we can manually run the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling automatic function calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Call:\n",
      "id=None args={'location': 'Boston, MA'} name='get_current_weather'\n",
      "Text Generated: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from gc import disable\n",
    "from google.genai import types\n",
    "\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return 'winter'\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='What is the weather today in boston?',\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[get_current_weather],\n",
    "        automatic_function_calling = types.AutomaticFunctionCallingConfig(disable=True)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Function Call:\")\n",
    "print(response.candidates[0].content.parts[0].function_call)\n",
    "\n",
    "print(\"Text Generated: \")\n",
    "print(response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not disabling automatic function calling: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Call Generated:\n",
      "None\n",
      "Text Generated: \n",
      "It is winter in Boston today.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gc import disable\n",
    "from google.genai import types\n",
    "\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "      location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return 'winter'\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='What is the weather today in boston?',\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[get_current_weather],\n",
    "        automatic_function_calling = types.AutomaticFunctionCallingConfig(disable=False)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"Function Call Generated:\")\n",
    "print(response.candidates[0].content.parts[0].function_call)\n",
    "\n",
    "print(\"Text Generated: \")\n",
    "print(response.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lessons: \n",
    "- The two examples above shows the difference between disabling and not disabling automatic function calling. if we disable automatic function calling, it will only return the function at the end of the day and not return the associated text, because the SDK cannot automatically run the function in order to obtain the function return result and incorporate it to form an answer\n",
    "- If we do not disable the automatic function calling, it does not return any Function Call parts in the return content. Instead, it automatically runs the function and then incorporate the return result of the function to form a text output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting maximum cap on the number of automatic tool call: \n",
    "- We can set the maximum number of function call that a model can make automatically in one API call. to do that, we can use the automatic_function_calling attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example below, the LLM can only automatically invoke function for 1 time. If we want to set the maximum number of function call to `x`, then we must set the maximum_remote_calls' number to `x+1`. For example, if we set the maximum_remote_calls to 2, then the LLM have a maximum automatic function call limit equal to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "def get_current_weather(location: str) -> str:\n",
    "    \"\"\"Returns the current weather.\n",
    "\n",
    "    Args:\n",
    "        location: The city and state, e.g. San Francisco, CA\n",
    "    \"\"\"\n",
    "    return \"sunny\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=\"What is the weather like in Boston?\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        tools=[get_current_weather],\n",
    "        automatic_function_calling=types.AutomaticFunctionCallingConfig(\n",
    "            maximum_remote_calls=2\n",
    "        ),\n",
    "        tool_config=types.ToolConfig(\n",
    "            function_calling_config=types.FunctionCallingConfig(mode='ANY')\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration of tool_config in the config argument "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tool Definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(location: str) -> str:\n",
    "    return f\"It's always sunny in {location}!\"\n",
    "\n",
    "def get_fact(topic: str) -> str:\n",
    "    facts = {\n",
    "        \"dog\": \"Dogs are known for their loyalty.\",\n",
    "        \"cat\": \"Cats sleep for 70% of their lives.\",\n",
    "        \"tokyo\": \"Tokyo is the largest metropolitan area in the world.\"\n",
    "    }\n",
    "    return facts.get(topic.lower(), f\"No fact found for {topic}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"ANY\" mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model text response (mode=AUTO):\n",
      "[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'topic': 'Tokyo'}, name='get_fact'), function_response=None, text=None), Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=FunctionCall(id=None, args={'location': 'Tokyo'}, name='get_weather'), function_response=None, text=None)], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.0006122445687651634, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)]\n"
     ]
    }
   ],
   "source": [
    "config_auto = types.GenerateContentConfig(\n",
    "    tools=[get_weather, get_fact],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"ANY\")  # default, can omit\n",
    "    ),\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n",
    ")\n",
    "\n",
    "prompt_auto = \"Tell me a fact about Tokyo and what's the weather like in Tokyo? Do not use any of the tools\"\n",
    "\n",
    "response_auto = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt_auto,\n",
    "    config=config_auto\n",
    ")\n",
    "\n",
    "# print(\"\\nFunction call parts returned by the model (mode=AUTO):\")\n",
    "# for call in getattr(response_auto, \"function_calls\", []):\n",
    "#     print(call)\n",
    "\n",
    "print(\"\\nModel text response (mode=AUTO):\")\n",
    "print(response_auto.candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"AUTO\" Mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model text response (mode=AUTO):\n",
      "[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, file_data=None, thought_signature=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='I am sorry, I cannot fulfill your request. I do not have the ability to provide facts or weather information without using the available tools.\\n')], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, url_context_metadata=None, avg_logprobs=-0.12131346505263756, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)]\n"
     ]
    }
   ],
   "source": [
    "config_auto = types.GenerateContentConfig(\n",
    "    tools=[get_weather, get_fact],\n",
    "    tool_config=types.ToolConfig(\n",
    "        function_calling_config=types.FunctionCallingConfig(mode=\"AUTO\")  # default, can omit\n",
    "    ),\n",
    "    automatic_function_calling=types.AutomaticFunctionCallingConfig(disable=True)\n",
    ")\n",
    "\n",
    "prompt_auto = \"Tell me a fact about Tokyo and what's the weather like in Tokyo? Do not use any of the tools\"\n",
    "\n",
    "response_auto = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=prompt_auto,\n",
    "    config=config_auto\n",
    ")\n",
    "\n",
    "# print(\"\\nFunction call parts returned by the model (mode=AUTO):\")\n",
    "# for call in getattr(response_auto, \"function_calls\", []):\n",
    "#     print(call)\n",
    "\n",
    "print(\"\\nModel text response (mode=AUTO):\")\n",
    "print(response_auto.candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Lesson: \n",
    "- In both mode, we instruct the model not to use any tools. But when using \"ANY\" mode, the model still continue using tool, even if instructed not to do so. \n",
    "- In \"AUTO\" mode, the model actually stop using tools and reply in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Response Schema \n",
    "- In this section, we go through the technique that we can use to enforce LLM to generate JSON-structure output when responding to query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enforce JSON output, there are two ways in doing this:\n",
    "1. Using Pydantic Models \n",
    "2. Using python object\n",
    "\n",
    "Pros of using Pydantic over Python object:\n",
    "- By using Pydantic Model, the program will automatically verify if the output of the LLM matches the Pydantic model we defined. This automatic checking is not applied when we use Python object\n",
    "\n",
    "Pros of using Python Object:\n",
    "- We don't need to install the pydantic library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pydantic Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"United States\",\n",
      "  \"population\": 331000000,\n",
      "  \"capital\": \"Washington, D.C.\",\n",
      "  \"continent\": \"North America\",\n",
      "  \"gdp\": 23000000000000,\n",
      "  \"official_language\": \"English\",\n",
      "  \"total_area_sq_mi\": 3797000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "class CountryInfo(BaseModel):\n",
    "    name: str\n",
    "    population: int\n",
    "    capital: str\n",
    "    continent: str\n",
    "    gdp: int\n",
    "    official_language: str\n",
    "    total_area_sq_mi: int\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='Give me information for the United States. Dont write in JSON, write in plain text!!!',\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type='application/json',\n",
    "        response_schema=CountryInfo,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using python object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"United States\",\n",
      "  \"population\": 331000000,\n",
      "  \"capital\": \"Washington, D.C.\",\n",
      "  \"continent\": \"North America\",\n",
      "  \"gdp\": 23000000000000,\n",
      "  \"official_language\": \"English\",\n",
      "  \"total_area_sq_mi\": 3797000\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='Give me information for the United States. RETURN YOUR OUTPUT IN PLAIN TEXT, NOT JSON!!',\n",
    "    config=types.GenerateContentConfig(\n",
    "        response_mime_type='application/json',\n",
    "        response_schema={\n",
    "            'required': [\n",
    "                'name',\n",
    "                'population',\n",
    "                'capital',\n",
    "                'continent',\n",
    "                'gdp',\n",
    "                'official_language',\n",
    "                'total_area_sq_mi',\n",
    "            ],\n",
    "            'properties': {\n",
    "                'name': {'type': 'STRING'},\n",
    "                'population': {'type': 'INTEGER'},\n",
    "                'capital': {'type': 'STRING'},\n",
    "                'continent': {'type': 'STRING'},\n",
    "                'gdp': {'type': 'INTEGER'},\n",
    "                'official_language': {'type': 'STRING'},\n",
    "                'total_area_sq_mi': {'type': 'INTEGER'},\n",
    "            },\n",
    "            'type': 'OBJECT',\n",
    "        },\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caveat: Although we have told the LLM to use JSON in its output, there is no 100% guarantee that the LLM will always output in JSON format. That's why using Pydantic is useful. The reason is because by using Pydantic, there will be auto-checking mechanism which will return validation error in case the output is not in JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enum Response Schema\n",
    "- This is used to enforce LLM to return one of the enum values as the response to a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class InstrumentEnum(Enum):\n",
    "    PERCUSSION = 'Percussion'\n",
    "    STRING = 'String'\n",
    "    WOODWIND = 'Woodwind'\n",
    "    BRASS = 'Brass'\n",
    "    KEYBOARD = 'Keyboard'\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='What instrument plays multiple notes at once?',\n",
    "    config={\n",
    "        'response_mime_type': 'text/x.enum',\n",
    "        'response_schema': InstrumentEnum,\n",
    "    },\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set response_mime_type to 'application.json', the response will be identical but in quotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Keyboard\"\n"
     ]
    }
   ],
   "source": [
    "class InstrumentEnum(Enum):\n",
    "    PERCUSSION = 'Percussion'\n",
    "    STRING = 'String'\n",
    "    WOODWIND = 'Woodwind'\n",
    "    BRASS = 'Brass'\n",
    "    KEYBOARD = 'Keyboard'\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='What instrument plays multiple notes at once?',\n",
    "    config={\n",
    "        'response_mime_type': 'application/json',\n",
    "        'response_schema': InstrumentEnum,\n",
    "    },\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Content (Synchronous Streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elara traced the swirling patterns in the dust on the windowsill, the afternoon sun warming her cheek. Outside, the Whispering Woods rustled with secrets, a language she’d always longed to understand. Her grandmother, Nana Iris, had sworn the woods held forgotten magic, but Elara’s parents called it superstition.\n",
      "\n",
      "Nana Iris was gone now, and the old cottage felt hollow. Her only inheritance was a worn, leather-bound journal filled with cryptic drawings and faded ink. Elara flipped through the pages, frustration growing. One entry, however, caught her eye: \"Where the willow weeps, the answer sleeps.\"\n",
      "\n",
      "The largest willow in the Whispering Woods stood sentinel by the creek, its branches brushing the water. Heart pounding, Elara set off, journal clutched in her hand. The woods, usually intimidating, felt different today, almost welcoming.\n",
      "\n",
      "Reaching the willow, she noticed a peculiar knot in the trunk, shaped like a closed eye. Following the journal’s sketch, she pressed on the knot. A section of bark swung inward, revealing a small cavity. Inside lay a single, smooth, grey stone.\n",
      "\n",
      "Elara picked it up. As her fingers brushed its surface, a wave of warmth washed over her. Images flooded her mind – Nana Iris tending a garden bursting with vibrant flowers, laughing with children, her eyes sparkling with joy. She saw her grandmother using the stone to coax life from barren earth.\n",
      "\n",
      "The images faded, leaving Elara breathless. The stone, she realized, wasn’t just a rock; it was a conduit to Nana Iris’s spirit, a key to unlocking the magic within herself. She held it tight, the whispering woods suddenly feeling less lonely, more like a home. Her grandmother may be gone, but her magic, and her love, lived on within her.\n"
     ]
    }
   ],
   "source": [
    "for chunk in client.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n",
    "):\n",
    "    print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Models.generate_content_stream at 0x123379800>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When iterating over Client.models.generate_content_stream, we are essentially iterating over an array that is not completed yet and we are still receiving it chunk-by-chunk. To understand how it works, we need to understand how generator works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generator is a special type of function in Python that lets you produce a sequence of values one at a time, instead of all at once.\n",
    "Each time the generator yields a value, it pauses and \"remembers\" where it left off—so on the next iteration, it continues right after the last yield.\n",
    "\n",
    "This means:\n",
    "\n",
    "The generator doesn’t compute or store all values at once (saving memory).\n",
    "You can use a for loop to process each value as it’s produced.\n",
    "Here’s an example of a simple generator that returns the square of each number from 0 up to (but not including) nums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "def square_numbers(nums):\n",
    "    for i in range(nums):\n",
    "        yield(i*i)\n",
    "\n",
    "for item in square_numbers(5):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is simple demonstration of how Gemini streaming works. As you can see, at any given point, there is a 0.1 probability that the stream will stop. This is similar to the case of Gemini, when there is no certainty as to when the model will stop generating token. As you can see by running the cell below, the for loop can still work even if the output is not available immediately (there is a sleep method to simulate network delay). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story streaming output:\n",
      "\n",
      "[Model decides to end stream early!]\n",
      "\n",
      "\n",
      "[End of stream, for-loop stops!]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "def fake_gemini_stream_dynamic(prompt):\n",
    "    # We'll simulate the model potentially generating an unpredictable number of chunks\n",
    "    words = [\n",
    "        \"Once\", \"upon\", \"a\", \"time,\", \"in\", \"a\", \"land\", \"far\", \"away,\",\n",
    "        \"there\", \"lived\", \"a\", \"cat\", \"named\", \"Luna.\", \"She\", \"loved\", \"adventure.\"\n",
    "    ]\n",
    "    idx = 0\n",
    "    while idx < len(words):\n",
    "        # Simulate the LLM randomly deciding to stop early\n",
    "        if random.random() < 0.1:  # 10% chance to stop after each chunk\n",
    "            print(\"\\n[Model decides to end stream early!]\\n\")\n",
    "            break\n",
    "        time.sleep(0.8)\n",
    "        yield words[idx] + ' '\n",
    "        idx += 1\n",
    "    # When we break or finish, the generator ends and StopIteration is raised\n",
    "\n",
    "print(\"Story streaming output:\")\n",
    "for chunk in fake_gemini_stream_dynamic(\"Tell me a story\"):\n",
    "    print(chunk, end='', flush=True)\n",
    "\n",
    "print(\"\\n[End of stream, for-loop stops!]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is MIME Type? \n",
    "- MIME type (Multipurpose Internet Mail Extensions) is a standard way to indicate the type and format of a file on the internet.\n",
    "- There are many different MIME type. Some example of image MIME types:\n",
    "    1. image/jpeg\n",
    "    2. image/png\n",
    "    3. image/gif\n",
    "- Other types of MIME Type:\n",
    "    1. audio/mpeg\n",
    "    2. audio/wav \n",
    "    3. text/html\n",
    "    4. application/json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alright, let's dive deep into the description of this image!\n",
      "\n",
      "The image is a close-up, high-quality photograph of a cat's face, predominantly focusing on the upper half of its body. The composition is intimate, filling the frame with the animal’s features and cutting off parts of the body, creating a sense of immediacy and drawing the viewer's attention entirely to the subject's face.\n",
      "\n",
      "**Background:**\n",
      "The background is a stark, pure white. The simplicity of the backdrop serves to isolate the cat and highlight its colors, textures, and details without any distractions. It gives the image a clean, modern feel, often seen in professional pet portraits. The evenness of the lighting on the background suggests a controlled studio environment, potentially using a light box or softboxes to create a consistent and shadowless field.\n",
      "\n",
      "**The Cat:**\n",
      "The cat is a stunning example of feline beauty. Its coat is bi-colored, featuring a blend of grey or bluish-grey (often referred to as \"blue\") and white. The distribution of these colors on the cat’s fur is striking. The top of the head, including the ears, is predominantly covered in the smooth gray fur, while the face has a distinct white patch extending from the forehead, down the bridge of the nose, and encompassing the muzzle and chest.\n",
      "\n",
      "**Fur Details:**\n",
      "The fur itself appears short and dense. The texture is visible with a slight fluffiness to it, especially around the edges where the white fur meets the grey. Individual hairs are discernible, particularly in the areas with denser fur, revealing the fine texture and subtle variations in color that contribute to the coat's overall appearance. The lighting helps accentuate this texture, casting subtle shadows that add depth and dimension.\n",
      "\n",
      "**Eyes:**\n",
      "The cat's eyes are arguably the most captivating feature of the image. They are large, round, and vibrantly colored, displaying a stunning golden-yellow hue, though closer inspection reveals a complex multi-tonal mix of yellows, oranges, and greens radiating from the pupil. The eyes are highly reflective, with subtle highlights indicating moisture, suggesting that the cat is alert and healthy. The pupils are dilated, giving the cat an open, expressive look.\n",
      "\n",
      "**Facial Features:**\n",
      "\n",
      "*   **Ears:** The cat's ears are triangular in shape, pointing upwards, and slightly angled outward. The inner surfaces of the ears have a delicate pinkish tone, contrasting with the gray fur that covers the outer surfaces. Fine, light-colored hairs are visible inside the ears, adding to the detail.\n",
      "*   **Nose:** The nose is a small, charmingly pink button, located centrally on the face. The delicate pink shade provides a gentle contrast against the surrounding white fur. The texture of the nose appears smooth and slightly glossy, suggesting a healthy, well-hydrated animal.\n",
      "*   **Whiskers:** Thin, white whiskers extend from both sides of the muzzle. These sensory hairs are prominent and add to the cat's expressive features. The whiskers are long and tapered, arching gracefully away from the face.\n",
      "*   **Facial Expression:** The cat has a curious and inquisitive expression. Its head is slightly tilted, as if it's attentively listening or watching something off-camera. The slight tilt combined with the open, alert eyes creates a charming and endearing gaze.\n",
      "\n",
      "**Lighting and Composition:**\n",
      "\n",
      "*   **Lighting:** The image is well-lit, with soft, diffused light illuminating the cat's face. The absence of harsh shadows allows for a clear view of the cat's features and textures. The lighting also enhances the vibrancy of the cat's eye color and the contrast between the gray and white fur.\n",
      "*   **Composition:** The composition is tightly framed, focusing mainly on the cat's face. This close-up perspective emphasizes the cat's features and creates a sense of intimacy. The cat is positioned slightly off-center, which adds visual interest to the image. The rule of thirds isn't strictly adhered to, but the subject is placed in such a way that it engages the viewer's eye.\n",
      "\n",
      "**Overall Impression:**\n",
      "The photograph is a beautifully executed portrait that captures the essence of feline charm and elegance. It's likely intended to evoke feelings of affection and admiration for cats, emphasizing their captivating eyes, soft fur, and expressive features. The high-quality execution and attention to detail suggest the work of a skilled photographer with an appreciation for animal portraiture.\n",
      "\n",
      "In summary, this image is a professional, high-resolution portrait of a bi-colored cat (gray and white) against a clean white background, showcasing its striking golden-yellow eyes, soft fur, and inquisitive expression, all bathed in soft, diffused light. The image is both aesthetically pleasing and emotionally engaging, drawing the viewer into a connection with the feline subject.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "YOUR_IMAGE_PATH = 'pexels-pixabay-104827.jpg'\n",
    "YOUR_IMAGE_MIME_TYPE = 'image/jpeg'\n",
    "with open(YOUR_IMAGE_PATH, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "for chunk in client.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents=[\n",
    "        'What is this image about? Make a very long and comprehensive description of this!',\n",
    "        types.Part.from_bytes(data=image_bytes, mime_type=YOUR_IMAGE_MIME_TYPE),\n",
    "    ],\n",
    "):\n",
    "    print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Content Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old lighthouse keeper, Silas, squinted at the swirling mist. He’d seen a hundred storms lash against the craggy coast, but this felt different. The fog was thick, heavy, and held a strange, unsettling quiet. Even the gulls had vanished.\n",
      "\n",
      "He checked the lamp, its beam cutting through the oppressive gloom, a lifeline for any lost ship. He sipped his lukewarm coffee, the tin cup clanging against the silence. Usually, the rhythmic crash of waves was his constant companion, a comforting drone. Tonight, only the mournful groan of the old lighthouse resonated.\n",
      "\n",
      "Suddenly, a single, sharp knock echoed from the heavy wooden door downstairs. Silas froze. No one ever came here. He gripped the heavy iron poker beside the stove.\n",
      "\n",
      "\"Who's there?\" he called, his voice raspy with disuse.\n",
      "\n",
      "Silence.\n",
      "\n",
      "He cautiously descended the winding stairs, the poker held high. He peered through the small peephole. Nothing. He unbolted the door, heart pounding.\n",
      "\n",
      "Standing on the slick, moss-covered stones was a small girl, no older than five, her face pale and tear-streaked. She wore a thin, soaked nightgown.\n",
      "\n",
      "\"Lost,\" she whispered, her voice barely audible above the wind. \"Mommy…\"\n",
      "\n",
      "Silas knelt, his gruff exterior crumbling. \"Come in, child. You're safe now.\"\n",
      "\n",
      "He wrapped her in a warm blanket, the little girl clinging to him like a lifeline. As he held her, he noticed something glinting on her tiny hand. A seashell, unlike any he’d ever seen, shimmering with an unnatural luminescence. He looked out at the swirling fog, and for a fleeting moment, thought he saw the faint outline of a ship vanishing into the mist. Perhaps this wasn’t just a storm after all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# asynchronous non-streaming\n",
    "response = await client.aio.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lighthouse keeper, Silas, squinted at the horizon. He'd seen worse storms, swirling monstrosities that rattled the windows and threatened to swallow the island whole. This one, however, felt different. An unnerving silence preceded the usual cacophony of wind and waves. Just a thick, impenetrable fog.\n",
      "\n",
      "Silas patted the lamp affectionately. Old Bess, they called her. Her beam, a steadfast finger pointing defiance at the tempest, was his only company. He fueled her meticulously, ensuring her flame danced bright and strong. He was a shepherd of the sea, guarding ships from the treacherous rocks.\n",
      "\n",
      "Hours crawled by. The fog thickened, pressing against the lighthouse like a suffocating blanket. Then, the silence broke. Not with a roar, but with a whisper. A haunting, mournful song carried on the wind, a melody that chilled Silas to the bone. It was unlike any siren song he'd ever heard, laced with sorrow and longing.\n",
      "\n",
      "He peered into the swirling gray, his heart pounding. Was it his imagination, or was there something moving in the fog? A shape, indistinct and shifting. He strained his eyes, gripping the railing. The song grew louder, drawing closer.\n",
      "\n",
      "Suddenly, a figure emerged. Not a siren, but a woman, draped in seaweed and shimmering with seawater. Her eyes, pools of infinite sadness, locked with his. She raised a hand, beckoning him.\n",
      "\n",
      "Silas felt an overwhelming urge to go to her, to comfort her sorrow. But the beam of Old Bess, unwavering and constant, reminded him of his duty. He tightened his grip, his gaze fixed on the lamp.\n",
      "\n",
      "The woman lingered for a moment, her song fading into a sigh. Then, she dissolved back into the fog, leaving Silas alone with the silence and the knowledge that some sorrows, even a lighthouse keeper cannot mend. The storm never came, but Silas knew, some storms leave no physical wreckage, only an echo in the heart.\n"
     ]
    }
   ],
   "source": [
    "# asynchronous streaming\n",
    "async for chunk in await client.aio.models.generate_content_stream(\n",
    "    model='gemini-2.0-flash-001', contents='Tell me a story in 300 words.'\n",
    "):\n",
    "    print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demonstration on the difference between asynchronous streaming and synchronous streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronous streaming demo (blocks other work):\n",
      "[SYNC] Chunk 0\n",
      "[SYNC] Chunk 1\n",
      "[SYNC] Chunk 2\n",
      "[SYNC] Chunk 3\n",
      "[SYNC] Chunk 4\n",
      "    [Other work] Step 0\n",
      "    [Other work] Step 1\n",
      "    [Other work] Step 2\n",
      "    [Other work] Step 3\n",
      "    [Other work] Step 4\n",
      "Total time: 6.5s\n"
     ]
    }
   ],
   "source": [
    "# synchronous streaming\n",
    "import time\n",
    "\n",
    "def sync_stream():\n",
    "    for i in range(5):\n",
    "        time.sleep(1)  # Simulate waiting for a chunk\n",
    "        print(f\"[SYNC] Chunk {i}\")\n",
    "\n",
    "def do_other_work():\n",
    "    for i in range(5):\n",
    "        print(f\"    [Other work] Step {i}\")\n",
    "        time.sleep(0.3)\n",
    "\n",
    "print(\"Synchronous streaming demo (blocks other work):\")\n",
    "start = time.time()\n",
    "sync_stream()\n",
    "do_other_work()\n",
    "print(f\"Total time: {time.time()-start:.1f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Asynchronous streaming demo (streams + does other work at the same time):\n",
      "Start Async Stream\n",
      "Start Other Work\n",
      "    [Other work] Step 0\n",
      "    [Other work] Step 1\n",
      "    [Other work] Step 2\n",
      "    [Other work] Step 3\n",
      "[ASYNC] Chunk 0\n",
      "    [Other work] Step 4\n",
      "[ASYNC] Chunk 1\n",
      "[ASYNC] Chunk 2\n",
      "[ASYNC] Chunk 3\n",
      "[ASYNC] Chunk 4\n",
      "Total time: 5.0s\n"
     ]
    }
   ],
   "source": [
    "# asynchronous streaming\n",
    "import asyncio\n",
    "\n",
    "async def async_stream():\n",
    "    print(\"Start Async Stream\")\n",
    "    for i in range(5):\n",
    "        await asyncio.sleep(1)  # Simulate waiting for a chunk\n",
    "        print(f\"[ASYNC] Chunk {i}\")\n",
    "\n",
    "async def async_other_work():\n",
    "    print(\"Start Other Work\")\n",
    "    for i in range(5):\n",
    "        print(f\"    [Other work] Step {i}\")\n",
    "        await asyncio.sleep(0.3)\n",
    "\n",
    "async def main():\n",
    "    print(\"\\nAsynchronous streaming demo (streams + does other work at the same time):\")\n",
    "    start = time.time()\n",
    "    await asyncio.gather(\n",
    "        async_stream(),\n",
    "        async_other_work()\n",
    "    )\n",
    "    print(f\"Total time: {time.time()-start:.1f}s\")\n",
    "\n",
    "# To run the async part in a notebook or script:\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens=7 cached_content_token_count=None\n"
     ]
    }
   ],
   "source": [
    "# Synchronous\n",
    "response = client.models.count_tokens(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='why is the sky blue?',\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens=7 cached_content_token_count=None\n"
     ]
    }
   ],
   "source": [
    "# Asynchronous\n",
    "response = await client.aio.models.count_tokens(\n",
    "    model='gemini-2.0-flash-001',\n",
    "    contents='why is the sky blue?',\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings=[ContentEmbedding(values=[0.0491829, 0.013741683, -0.0004936165, -0.0053853146, -0.04791199, -0.02840196, 0.021883618, 0.0020781786, 0.037686065, 0.03087265, -0.06576896, -0.009556199, 0.09558417, -0.034034792, -0.0156428, -0.05640331, -0.04274169, -0.010626148, -0.03084156, 0.032389797, 0.055554155, -0.00088076066, 0.041391667, 0.0017034768, -0.019586, 0.055602096, 0.028125113, 0.048383057, -0.051416468, -0.01682559, 0.039197855, -0.0020786228, -0.0048818626, -0.04145468, -0.005534551, 0.029501924, -0.016523024, 0.018552564, 0.00067175005, 0.010499649, -0.042587113, 0.026342036, -0.011970505, 0.03458699, 0.0027072534, -0.018511586, 0.055825762, 0.034498554, 0.00520742, 0.074566245, 0.031152407, 0.017485237, -0.044427674, 0.030369414, 0.020307822, -0.027352024, -0.018360065, 0.07116467, 0.088631265, -0.0014887183, -0.04542823, -0.022819376, -0.03223622, 0.005833082, -0.046683654, -0.026722396, -0.050615557, 0.015309006, 0.009370212, 0.051415388, -0.004606239, 0.08460135, -0.033844236, 0.027208177, -0.011010169, 0.008797841, -0.016343992, 0.011766489, -0.024080537, 0.0017989561, -0.058822174, 0.030784763, 0.07183485, 0.07082987, 0.0541927, -0.0037466714, 0.0031073417, 0.010162787, -0.0554912, 0.0044004545, -0.047410313, -0.028987387, -0.0038734274, -0.026009986, 0.025802415, 0.027167434, -0.011137672, -0.11617528, 0.06883703, -0.012847598, -0.01950887, 0.004833421, -0.0375025, -0.074691094, 0.053239975, 0.04154621, 0.026953107, -0.025524994, -0.02544026, -0.03657161, -0.03209452, -0.0054825353, 0.06745612, 0.04905617, -0.024259558, -0.08067334, -0.028259913, -0.007340103, -0.036380883, 0.055496093, -0.0011972148, -0.0073731104, -0.044960536, 0.03160285, -0.023569623, 0.0010606124, -0.011345415, 0.016518703, -0.014378749, 0.027270947, 0.011739485, -0.04044344, 0.008686229, 0.031049013, -0.076631784, 0.01382957, 0.07054112, -0.03158478, 0.03685539, -0.057485517, 0.012674261, 0.033473365, -0.062198054, -0.05712399, 0.025265532, 0.016723758, -0.007863538, -0.01970526, -0.009753946, 0.021779975, 0.028041292, -0.0038700646, 0.03502537, -0.012496848, -0.018653015, -0.030959781, 0.06470351, -0.007453704, 0.07224308, -0.013224034, 0.027940325, 0.006183228, 0.013551654, -0.0037205648, -0.019767426, 0.017236287, -0.015889972, 0.0066311187, 0.033975217, 0.007728805, 0.009139557, -0.07701651, -0.0061981934, -0.038596902, -0.04534227, -0.012142488, 0.037514117, -0.08575057, -0.0037731824, -0.08488688, 0.015113562, -0.011484875, -0.016465135, -0.08045097, 0.03361648, -0.0007034833, 0.008290858, 0.0018316577, 0.072653465, 0.017004848, -0.043236036, 0.058142662, 0.022896647, 0.0009917284, -0.0063473047, -0.035124112, 0.04256822, -0.051858492, 0.012803382, 0.036228854, -0.0035843519, 0.051390275, 0.011022434, -0.0061761294, 0.0028446682, 0.0023261458, -0.057455353, 0.024029067, 0.023478862, 0.036218725, 0.012709147, -0.004849339, -0.016703786, -0.054962043, 0.06886422, 0.023678152, 0.06609507, 0.023343729, 0.07573917, 0.00078254205, 0.024956115, 0.012966457, 0.07065637, 0.003938486, -0.026351579, 0.0042059585, -0.009918651, -0.052664448, -0.0211653, -0.018400174, 0.033807933, -0.024586739, -0.048905496, -0.009807739, -0.012746362, 0.00080054865, -0.0030214535, -0.032658827, 0.012223454, -0.013348838, -9.230329e-05, -0.08072465, 0.017922709, -0.025637984, 0.0012540163, -0.0050590625, 0.04114819, 0.06101682, 0.032426223, -0.07900822, -0.029734943, -0.022049466, -0.017619465, 0.00476147, -0.066475764, -0.08948393, 0.032082357, -0.06104412, -0.004649328, -0.038381077, 0.010732633, -0.024262998, -0.040166494, -0.07722144, -0.083528295, -0.03126523, -0.045157515, 0.021832447, 0.0018345669, -0.015732702, 0.06281894, 0.020098021, -0.02017973, -0.005094717, -0.025993554, 0.06564324, 0.014496344, 0.01627141, 0.034371316, -0.06157389, 0.051020704, 0.026169378, -0.040160652, 0.024716193, 0.042481747, -0.06518291, 0.021758685, -0.021270502, 0.008391182, -0.021335412, 0.033224903, -0.006324451, -0.010905178, -0.022620656, 0.054355655, 0.005125226, 0.013851813, 0.01151227, 0.008053041, -0.036331486, 0.022019027, 0.052123014, -0.04654223, 0.0069147917, -0.010675014, -0.006764442, -0.023709781, -0.0046915025, -0.040900238, 0.009132791, -0.030344475, 0.009314251, -0.026035452, 0.022887917, -0.034832593, -0.044876613, -0.03807552, -0.039642926, -0.029938623, -0.015595056, -0.016412633, -0.010356508, 0.011179579, 0.060744, 0.07352512, -0.073335975, -0.021530826, 0.015131503, -0.034605544, -0.017989907, 0.017607922, -0.009695468, 0.026636144, -0.050523885, -0.0060041333, 0.04000291, -0.06405382, 0.04821524, 0.029780379, 0.029197657, -0.03448302, 0.019532673, -0.0053177867, 0.08156353, 0.032544736, -0.016708888, 0.030665314, 0.024841476, -0.011029452, -0.045650978, 0.00447242, 0.024603106, 0.07522107, -0.03558999, -0.050186947, -0.007842377, 0.021752223, -0.015047801, 0.012783095, -0.026027171, -0.0011757155, -0.0041782903, 0.0034546931, -0.013732015, 0.034089893, 0.028431535, 0.005202291, 0.005178129, 0.0038663603, -0.071980216, 0.023518557, -0.0534037, -0.03533719, -0.04250972, -0.016007984, -0.022112297, -0.0047773556, -0.018256586, 0.013867888, -0.059377763, -0.013979277, -0.020387322, -0.05632369, 0.0074116257, -0.0022445563, 0.03347548, -0.016808713, 0.007531889, 0.0006899846, -0.016073985, -0.04620479, 0.03936625, -0.028920883, 0.023674963, 0.0014632, 0.034974243, -0.044552628, 0.06589813, 0.049761802, 0.02653847, -0.017956426, 0.006253169, 0.06082533, -0.016249172, -0.05931278, -0.019909432, 0.031969834, 0.030020414, 0.06667178, -0.017940557, -0.04856787, -0.013704937, 0.03137649, 0.020610228, -0.0057233204, -0.00826051, 0.023931056, 0.02678677, 0.04513913, 0.0012558203, -0.012084739, 0.02618783, -0.03167547, -0.027933782, -0.002093475, -0.039041072, -0.010950522, 0.008059322, -0.005626885, 0.042056702, 0.037333667, 0.023772521, 0.04044822, 0.005899236, 0.003570654, -0.016603863, -0.04993869, 0.017643124, -0.031245658, 0.024744129, 0.0064788675, 0.015049761, -0.020298202, -0.015501144, 0.020272523, -0.034193557, 0.0007488635, -0.06971633, -0.011347671, 0.02686092, -0.01771921, -0.0173582, -0.024327625, -0.020494912, -0.040839367, 0.02285389, 0.005738871, 0.076273404, 0.053321086, -0.0069216792, -0.027066255, -0.022319991, 0.082845956, 0.011740658, -0.0020094705, -0.0041359244, -0.00039157408, -0.0073817037, 0.017986834, -0.020672427, -0.007391526, 0.019167418, 0.0096702585, 0.019250136, -0.037666816, -0.004577848, -0.0073925364, 0.0068027945, -0.034404304, 0.004179811, 0.068566576, 0.043285433, -0.028303226, 0.0854909, 0.030193813, -0.024494842, -0.0044911997, -0.011278603, -0.010424351, -0.009348893, -0.018390864, 0.023594689, 0.013791961, -0.049456682, -0.045820903, -0.0021318602, 0.042546548, 0.010774103, 0.010385963, 0.06749493, 0.041684777, 0.0018098175, 0.024304124, 0.011723339, 0.011599345, -0.018338626, 0.007311424, -0.042587772, 0.0052352254, 0.0076380223, 0.059190515, -0.032750748, -0.014771376, -0.006358192, 0.01456572, -0.006495783, 0.02707419, 0.0818821, -3.2476248e-05, 0.05539602, 0.008149279, 0.011353294, 0.07198729, -0.05395549, 0.038129073, -0.0007815657, -0.008227141, 0.02833902, 0.05160907, -0.012219548, -0.04753543, 0.004051663, 0.036582906, -0.004553469, -0.02985626, 0.03587621, -0.00147489, 0.055432476, -0.04988452, 0.021251751, 0.061466213, 0.029583754, 0.06199603, 0.07007059, 0.08092691, -0.029783744, 0.039717387, 0.04560318, -0.0063168686, 0.045853835, 0.082351916, -0.008354057, 0.011652028, -0.05765253, -0.028554581, -0.028458769, 0.03898275, 0.025099918, -0.03698047, 0.024495207, 0.053070426, -0.020873176, 0.012895207, 0.020239392, -0.0056084753, 0.00693964, -0.04357745, 0.050619442, -0.03423839, 0.023292312, 0.020367358, 0.0042333417, -0.029375546, -0.042888913, 0.07312829, -0.00164033, -0.0578848, -0.011353434, -0.03796458, -0.029307922, -0.0021005366, -0.0016639278, 0.019421462, 0.051014937, 0.00856508, 0.01730317, -0.010020875, 0.018894821, 0.028677389, -0.030725438, 0.013371141, 0.019424157, 0.0003486731, -0.031885713, 0.029737925, -0.023688104, 0.009418517, 0.023306085, -0.02764258, 0.05266359, -0.013480968, -0.03865096, 0.03755083, -0.035808988, -0.028493803, -0.025400653, -0.00031754872, -0.0057505784, -0.03674965, -0.018579116, -0.0009420272, 0.009096879, -0.034310244, -0.015687572, -0.0727299, -0.038107608, -0.030949403, -0.009693994, 0.0056555807, -0.002974593, -0.06447414, -0.0029920952, 0.0010172091, 0.016503077, -0.12422683, 0.030048108, 0.029873133, -0.0060133934, -0.102353655, 0.034963857, -0.0013821459, 0.03043732, 0.031812992, 0.016108226, -0.07336435, -0.009893889, 0.017821841, -0.008389829, -0.0033127102, -0.025133947, 0.017348722, 0.04298732, -0.007726862, 0.048965905, -0.029226674, 0.028452536, 0.0061407518, 0.008984014, 0.0052326014, 0.013588085, -0.0444065, -0.014699926, 0.038750127, -0.031389605, 0.040329758, 0.08725494, -0.017306214, 0.007181863, -0.02253374, 0.005217433, 0.039700218, -0.0674061, -0.06435947, -0.054989465, -0.01887831, 0.038835287, 0.016359188, 0.0007261985, -0.014250662, -0.011927866, -0.044839256, 0.034752835, -0.003520789, -0.017318577, -0.019376546, -0.020681787, 0.054497186, -0.0015963227, -0.0154903615, -0.00093166006, 0.022216849, -0.03559055, 0.038643353, 0.054688733, -0.02243698, 0.04290253, 0.020399153, 0.010134826, 0.06124263, 0.013826757, -0.02620523, 0.00122471, 0.0017840811, -0.015405299, -0.04424186, 0.021513194, -0.0190357, -0.01082237, -0.027364798, -0.03971204, -0.0018424992, 0.0006509256, -0.01651729, 0.0011071145, 0.040406436, -0.018912064, 0.100320734, -0.018709002, -0.09518459, 0.07792309, -0.025603848, 0.019721936, 0.04381488, 0.016677706, -0.030491067, 0.024455477, 0.011407982, 0.009188642, -0.010763929, -0.04141596, -0.024599882, -0.06763299, -0.007907401, 0.052259717, 0.023754898, 0.0031262836, -0.03950146, -0.024170293, -0.0033994268, 0.028910855, 0.0060955705, -0.0137297725, 0.013216967, -0.020712344, -0.04853566, 0.038085453, -0.0458019, -0.0037595695, 0.01317471, -0.06623965, -0.015976628, -0.033793893, 0.06685163, -0.041677568, -0.0078000766, 0.01764509, 0.023942472, -0.04036421, -0.038670845, -0.004605197, -0.13396588, -0.029765805, -0.01100552, 0.024016434, -0.03536023, -0.016736701, -0.0074717845, 0.0057111313, 0.0331701, 0.1021125, 0.011269163, 0.011126261, -0.026123837, 0.024560547, -0.07011508, 0.0021720186, -0.030823095, -0.052955955], statistics=None)] metadata=None\n"
     ]
    }
   ],
   "source": [
    "response = client.models.embed_content(\n",
    "    model='text-embedding-004',\n",
    "    contents='why is the sky blue?',\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings=[ContentEmbedding(values=[0.0491829, 0.013741683, -0.0004936165, -0.0053853146, -0.04791199, -0.02840196, 0.021883618, 0.0020781786, 0.037686065, 0.03087265], statistics=None), ContentEmbedding(values=[-0.03537547, -0.009187652, -0.08272189, 0.013758232, -0.0009691877, 0.046134237, 0.00861565, -0.014853918, -0.03661013, 0.009378613], statistics=None)] metadata=None\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# multiple contents with config\n",
    "response = client.models.embed_content(\n",
    "    model='text-embedding-004',\n",
    "    contents=['why is the sky blue?', 'What is your age?'],\n",
    "    config=types.EmbedContentConfig(output_dimensionality=10),\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Story:\n",
      "The lighthouse keeper, Silas, was a man of routine. Every evening, as the sun dipped below the churning horizon, painting the sky in hues of fiery orange and bruised purple, he would climb the winding stairs of the old stone tower. He'd meticulously polish the great lens, its brass frame gleaming, and then, with a practiced hand, ignite the lamp. The beam would cut through the gathering darkness, a loyal beacon for ships lost in the sea's vast indifference.\n",
      "\n",
      "For thirty years, Silas had lived this life. Thirty years of salt-laced wind, the mournful cry of gulls, and the rhythmic crash of waves against the rocks. He'd seen storms rage and abate, ships sail past with their fleeting glimpses of distant lands, and the constant, unchanging face of the sea. He was a fixture, as much a part of the landscape as the lighthouse itself.\n",
      "\n",
      "One day, a storm, unlike any he'd witnessed before, descended upon the coast. The wind howled like a banshee, tearing at the lighthouse walls. Waves, monstrous and black, crashed over the rocky outcrop, threatening to engulf the tower entirely. Silas clung to the iron railing, his heart a drum against his ribs.\n",
      "\n",
      "Through the sheets of rain, he saw it. A small fishing vessel, tossed about like a cork in the tempest. Its lights flickered weakly, then vanished. Silas knew, with a certainty that chilled him to the bone, that they were in trouble.\n",
      "\n",
      "He hesitated. Protocol dictated he stay with the light. The storm was too ferocious, any attempt at rescue would be futile. But then, he saw it again, a brief flash of light, a desperate signal in the maelstrom.\n",
      "\n",
      "Silas made a decision. He grabbed his oilskins and his oldest, most reliable compass, and descended the winding stairs, his footsteps echoing in the hollow tower. He launched the small rescue boat, a frail craft against the raging sea. The waves slammed against him, soaking him to the bone, threatening to capsize him at any moment.\n",
      "\n",
      "He navigated by instinct and the memory of the fisherman’s fleeting light. For what felt like an eternity, he battled the storm. Just as he was about to give up, he saw them - three figures clinging to wreckage, barely alive.\n",
      "\n",
      "With Herculean effort, he managed to pull them aboard his small boat. They were shivering, exhausted, and terrified, but alive. He turned the boat back towards the lighthouse, a slow, agonizing journey against the relentless onslaught of the storm.\n",
      "\n",
      "Finally, they reached the shore. He helped the fishermen ashore, offering them dry clothes and warm soup from his meager supplies. He watched them, their faces etched with relief and gratitude, as they found their bearings.\n",
      "\n",
      "As the storm began to subside, and the first rays of dawn painted the sky, Silas climbed back up the lighthouse stairs. He was exhausted, battered, and soaked to the bone, but a warmth spread through him that he hadn't felt in years.\n",
      "\n",
      "He looked out at the calm that followed the storm. The sea, now tranquil and shimmering, reflected the dawn. He ignited the lamp, the familiar beam cutting through the retreating darkness.\n",
      "\n",
      "He hadn't stayed with the light. He'd risked everything. And he'd saved three lives.\n",
      "\n",
      "Silas knew, as he looked out at the horizon, that he was still a lighthouse keeper, but he was also something more. He was a hero. And that was a light that shone brighter than any lamp. The routine remained, but within it, a new meaning had been illuminated. He was not just a keeper of the light, but a beacon of hope in the face of the indifferent sea. And that, he realized, was a much greater responsibility, and a far more fulfilling life.\n",
      "\n",
      "Summarized Story:\n",
      "A solitary lighthouse keeper, bound by routine, risks his life in a treacherous storm to rescue three fishermen, discovering a deeper purpose beyond simply maintaining the light.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model='gemini-2.0-flash-001')\n",
    "response = chat.send_message('tell me a story')\n",
    "print(\"Original Story:\")\n",
    "print(response.text)\n",
    "print(\"Summarized Story:\")\n",
    "response = chat.send_message('summarize the story you told me in 1 sentence')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lighthouse keeper, Silas, was as weathered and stoic as the granite island his lantern illuminated. For fifty years, he'd been the guardian of this lonely outpost, his life a predictable rhythm of oiling gears, polishing lenses, and brewing strong, bitter coffee. He knew the language of the waves - their whisperings, their roars, their deceptive lulls. He knew the faces of the seabirds that nested on the cliffs, and the moods of the relentless wind.\n",
      "\n",
      "But Silas didn't know loneliness. He had the stars for company, the stories in his worn-out books, and the comforting pulse of the beam cutting through the dark. Until, one day, a small wooden box washed ashore, cradled in seaweed and barnacles.\n",
      "\n",
      "Inside, nestled on faded velvet, was a porcelain doll. She was exquisitely crafted, with delicate features, painted lashes, and a tiny, almost imperceptible smile. One of her arms was broken, and her painted dress was chipped, but she possessed a haunting beauty that captivated Silas.\n",
      "\n",
      "He hadn't held a doll, or any toy, since he was a boy. He felt a strange tug in his chest, a longing he hadn't realized he'd buried so deep. He mended her arm as best he could with glue and twine, and carefully cleaned her dress. He placed her on the windowsill, where the lighthouse beam would bathe her in its light.\n",
      "\n",
      "Days turned into weeks. Silas found himself talking to the doll, telling her about the storms, the ships that passed, and the mundane details of his life. He named her Annabelle. He’d catch himself adjusting her dress, smoothing her hair, and even humming old sea shanties for her.\n",
      "\n",
      "The island, which had always felt like a duty, now felt like a shared home. Annabelle became his companion, a silent confidante in his solitary world. He realized he hadn't been lonely, but isolated. He hadn't realized the difference until Annabelle arrived.\n",
      "\n",
      "One particularly stormy night, a fishing vessel radioed for help. They were caught in a rogue wave, their engine dead, and their situation dire. Silas, his voice calm and steady, guided them through the treacherous rocks with the help of the lighthouse beam. He kept them talking, offering words of encouragement until a rescue boat arrived.\n",
      "\n",
      "The next morning, exhausted but relieved, Silas went to check on Annabelle. He found her gone. The window was open, rattling in the wind, and the spot where she had sat was empty.\n",
      "\n",
      "Panic seized him. He searched everywhere, from the craggy cliffs to the sandy cove where she had been found. He called her name, his voice hoarse, lost in the roar of the waves.\n",
      "\n",
      "He found nothing.\n",
      "\n",
      "Despair settled over him, heavier than the fog that often blanketed the island. He felt the loneliness return, sharper and more profound than before. He had lost not just a doll, but a connection he hadn't known he needed.\n",
      "\n",
      "Days later, a small package arrived on the supply boat. Inside was a carefully wrapped note and Annabelle.\n",
      "\n",
      "The note was from one of the fishermen he had helped rescue. It read: \"Dear Silas, We found Annabelle on our boat after the storm. She kept us company through the night. My daughter, who loves dolls, wanted to keep her, but I knew she belonged to you. Thank you for saving us. We knew you were watching over us, guided by the light, and Annabelle’s silent promise to bring us home.\"\n",
      "\n",
      "Silas held Annabelle close. He placed her back on the windowsill. He realized he hadn't just saved a fishing boat; he had reminded himself of the human connection that binds us all, even in the most isolated of places. He was still the guardian of the lighthouse, but now, he was also a guardian of hope, a reminder that even a small, broken doll can bring light to the darkest of nights. And that was a story worth keeping alive.\n"
     ]
    }
   ],
   "source": [
    "# Synchronous Streaming\n",
    "chat = client.chats.create(model='gemini-2.0-flash-001')\n",
    "for chunk in chat.send_message_stream('tell me a story'):\n",
    "    print(chunk.text, end='')  # end='' is optional, for demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The wind howled a mournful song through the skeletal branches of the Whispering Woods, a sound Elara had grown accustomed to. Living on the edge of the woods, in a cottage cobbled together from scavenged timber and sheer will, she was more attuned to the forest's moods than the villagers of Oakhaven, who whispered she was a witch, best left undisturbed.\n",
      "\n",
      "Elara wasn't a witch. She was a Listener. She could hear the stories woven into the fabric of the woods – tales of ancient trees, forgotten creatures, and the secrets buried deep beneath the moss and roots. This gift, a blessing and a burden, was the reason she lived in isolation.\n",
      "\n",
      "One day, the wind brought a new song, a frantic, high-pitched keening unlike anything Elara had heard before. It led her deeper into the woods than she usually dared venture. There, nestled amongst the gnarled roots of an ancient oak, she found a baby griffin, its wing twisted at an unnatural angle.\n",
      "\n",
      "Its golden feathers were matted with dirt, its large, intelligent eyes wide with pain. Elara, despite her fear of drawing attention, couldn't abandon it. She gently scooped the griffin into her arms, ignoring the sharp pinch of its beak, and carried it back to her cottage.\n",
      "\n",
      "Days turned into weeks as Elara nursed the griffin back to health. She learned its language of chirps and purrs, feeding it scraps of meat and healing herbs gleaned from the forest floor. She named it Zephyr, for the gentle breeze that whispered through its feathers.\n",
      "\n",
      "As Zephyr grew, so did Elara's affection for it. She forgot the whispers of the villagers, forgot her fear of being different. She was no longer alone.\n",
      "\n",
      "But Zephyr wasn't a pet. It was a creature of the wild, destined to soar above the treetops. One crisp autumn morning, Zephyr spread its wings, now strong and whole, and looked at Elara, its golden eyes filled with gratitude. It nuzzled her hand, then launched itself into the sky, circling the cottage once before disappearing over the horizon.\n",
      "\n",
      "Elara felt a pang of loss, a sharp ache in her chest. She was alone again.\n",
      "\n",
      "But as the sun dipped below the horizon, painting the sky in hues of orange and purple, Elara heard a different song in the wind. It was Zephyr's song, carried on the breeze, a song of gratitude, of friendship, and of a promise to return.\n",
      "\n",
      "And Elara knew, as she sat by her hearth, listening to the wind, that she was never truly alone. She had touched a creature of the wild, healed its wounds, and in doing so, healed a part of herself. She had learned that connection wasn't about possession, but about understanding and letting go.\n",
      "\n",
      "The whispers of the villagers still reached her ears, but they no longer bothered her. For she was no longer just a Listener of the Woods. She was a friend, a healer, and a beacon of kindness in a world that often forgot to listen. And that, she realized, was a story worth living.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# asynchronous non-streaming\n",
    "chat = client.aio.chats.create(model='gemini-2.0-flash-001')\n",
    "response = await chat.send_message('tell me a story')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old lighthouse keeper, Silas, had seen things. Things the seabirds whispered about on stormy nights, things that shimmered in the heat haze above the waves, things that even the salt-crusted walls of the lighthouse seemed to absorb and then exhale with a mournful groan.\n",
      "\n",
      "For fifty years, he’d been the lone sentinel, a grizzled guardian against the treacherous reefs that guarded the coast. He’d seen ships swallowed whole by rogue waves, rescued sailors clinging to splintered debris, and even witnessed, once, a pod of whales singing in perfect harmony under the light of the full moon.\n",
      "\n",
      "But the thing he remembered most vividly, the thing that kept him awake on nights when the wind howled like a banshee, was the Mermaid.\n",
      "\n",
      "He hadn't seen her clearly, not at first. Just a flash of silver in the frothing sea, a glimpse of a long, dark tress cascading down a shimmering form. He'd dismissed it as a trick of the light, a figment of his imagination fueled by years of solitude.\n",
      "\n",
      "But then she came again. This time, she was closer. He saw her face, pale and ethereal, framed by the spray. Her eyes, the color of the deep sea, held a sadness that mirrored the vast, unknowable depths of the ocean itself. She didn't speak, but Silas felt a pang of understanding, a connection that transcended language.\n",
      "\n",
      "He started leaving gifts. Not jewels or trinkets, for he had none. He left polished stones, gathered from the beach, and vibrant seashells he’d found washed ashore. He'd place them on a flat rock just below the lighthouse during low tide, hoping she would find them.\n",
      "\n",
      "For months, he saw her sporadically. A fleeting glimpse in the dawn, a shadow beneath the waves at dusk. He never knew if she took his gifts, but the hope that she did kept him company.\n",
      "\n",
      "Then, one particularly brutal storm hit. The wind screamed, the waves crashed against the lighthouse with the force of a battering ram. Silas stayed at his post, tirelessly rotating the lamp, a beacon of hope in the raging darkness.\n",
      "\n",
      "As dawn broke, the storm finally began to subside. Silas, exhausted but relieved, scanned the horizon. And there she was.\n",
      "\n",
      "Washed ashore, lying limp on the sand.\n",
      "\n",
      "He rushed down the winding stairs, his old legs aching with the effort. He reached her side and saw the terrible truth. She was injured, a jagged gash across her tail, and her breath came in ragged gasps.\n",
      "\n",
      "Silas didn't hesitate. He gently lifted her, his calloused hands surprisingly tender, and carried her to the lighthouse. He laid her on a bed of seaweed and damp blankets, and he bathed her wound with saltwater, humming a mournful sea shanty he hadn't sung in years.\n",
      "\n",
      "He nursed her back to health, feeding her fish he caught himself, tending to her wound with seaweed poultices. He didn’t expect her to understand his words, but he talked to her anyway, telling her stories of his life, of the sea, of the things he'd seen.\n",
      "\n",
      "Days turned into weeks, and the Mermaid slowly recovered. She began to understand his simple gestures, to respond to his voice with a glimmer of recognition in her deep-sea eyes. He named her Maris, meaning \"of the sea.\"\n",
      "\n",
      "He knew she couldn't stay. She belonged to the ocean, not to his lonely lighthouse. And one morning, he knew the time had come. He led her to the water's edge, and she looked back at him, her eyes filled with a mix of gratitude and sorrow.\n",
      "\n",
      "Then, with a final, lingering glance, she slipped into the waves and disappeared.\n",
      "\n",
      "Silas returned to his lighthouse, his heart both heavy and strangely full. He knew he would probably never see her again, but he also knew he would never forget her. He had touched something magical, something beyond the realm of ordinary experience.\n",
      "\n",
      "Years passed. Silas continued to tend the lighthouse, his hair turning whiter, his movements slower. But he never felt truly alone. He knew that somewhere out there, in the vast and mysterious ocean, Maris was swimming free, and that a piece of her would always remain with him, a reminder of the day he saved a Mermaid.\n",
      "\n",
      "And sometimes, on nights when the moon was full and the sea was calm, he could almost hear her singing, a faint, ethereal melody carried on the wind, a song of gratitude and love, a song that only Silas could hear. And he knew, in his heart, that the sea had a secret, and that he, the old lighthouse keeper, had been chosen to keep it.\n"
     ]
    }
   ],
   "source": [
    "# Asynchronous Streaming\n",
    "chat = client.aio.chats.create(model='gemini-2.0-flash-001')\n",
    "async for chunk in await chat.send_message_stream('tell me a story'):\n",
    "    print(chunk.text, end='') # end='' is optional, for demo purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='files/jwom24m5fe0g' display_name=None mime_type='image/jpeg' size_bytes=764047 create_time=datetime.datetime(2025, 6, 7, 7, 41, 47, 19696, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 46, 893359, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 47, 19696, tzinfo=TzInfo(UTC)) sha256_hash='Njk4ODU1MTMxYzgzNjkwODEwZWNkYjIwODllYzg1YWM1YzlmN2Q1ZjMyNzQ0NmU2N2E0ZDYyNjcxOGQ0YjdkNA==' uri='https://generativelanguage.googleapis.com/v1beta/files/jwom24m5fe0g' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n"
     ]
    }
   ],
   "source": [
    "# The file uploaded is going to be expired in 2 days time \n",
    "# Uploaded file cannot be downloaded\n",
    "file1 = client.files.upload(file = \"pexels-pixabay-104827.jpg\")\n",
    "\n",
    "print(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = client.files.upload(file= \"pdf1.pdf\")\n",
    "file3 = client.files.upload(file = \"pdf2.pdf\")\n",
    "file4 = client.files.upload(file= \"pdf1.pdf\")\n",
    "file5 = client.files.upload(file = \"pdf2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = client.files.get(name=file1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files before deleted:\n",
      "name='files/matelw8nby4r' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 57, 508666, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 57, 377183, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 57, 508666, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/matelw8nby4r' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/o744s2nf66a9' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 55, 157335, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 55, 4073, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 55, 157335, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/o744s2nf66a9' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/35itdawsd32s' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 53, 267151, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 53, 221121, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 53, 267151, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/35itdawsd32s' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/0i6i49s0iqck' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 50, 900919, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 50, 698292, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 50, 900919, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/0i6i49s0iqck' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/jwom24m5fe0g' display_name=None mime_type='image/jpeg' size_bytes=764047 create_time=datetime.datetime(2025, 6, 7, 7, 41, 47, 19696, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 46, 893359, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 47, 19696, tzinfo=TzInfo(UTC)) sha256_hash='Njk4ODU1MTMxYzgzNjkwODEwZWNkYjIwODllYzg1YWM1YzlmN2Q1ZjMyNzQ0NmU2N2E0ZDYyNjcxOGQ0YjdkNA==' uri='https://generativelanguage.googleapis.com/v1beta/files/jwom24m5fe0g' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/mk4dzptc77av' display_name=None mime_type='text/plain' size_bytes=847790 create_time=datetime.datetime(2025, 6, 7, 7, 24, 57, 172444, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 24, 56, 975621, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 24, 57, 172444, tzinfo=TzInfo(UTC)) sha256_hash='MGQyN2JkYzNlMDU5ZDIwNjI3ZWQ4MjhhMzExMzhiMjk0ZDcwYjk5NmIwZjZjOGFkMWI1MzAyNmQyMDgzOTk1MQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/mk4dzptc77av' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/9c4ipcz8rl68' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 35, 917365, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 35, 876677, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 35, 917365, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/9c4ipcz8rl68' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/bogn6ldomfnz' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 33, 514165, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 33, 312342, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 33, 514165, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/bogn6ldomfnz' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/yuwq1z12cg9y' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 30, 846544, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 30, 653798, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 30, 846544, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/yuwq1z12cg9y' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/qlryulis8lo8' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 28, 182071, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 28, 135636, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 28, 182071, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/qlryulis8lo8' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/05f0a7qlel2s' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 24, 7, 854984, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 24, 7, 815546, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 24, 7, 854984, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/05f0a7qlel2s' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/whrx0qhib708' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 24, 5, 358136, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 24, 5, 136987, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 24, 5, 358136, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/whrx0qhib708' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/px2mewwx3ro4' display_name=None mime_type='image/jpeg' size_bytes=764047 create_time=datetime.datetime(2025, 6, 7, 3, 53, 54, 704628, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 3, 53, 54, 660587, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 3, 53, 54, 704628, tzinfo=TzInfo(UTC)) sha256_hash='Njk4ODU1MTMxYzgzNjkwODEwZWNkYjIwODllYzg1YWM1YzlmN2Q1ZjMyNzQ0NmU2N2E0ZDYyNjcxOGQ0YjdkNA==' uri='https://generativelanguage.googleapis.com/v1beta/files/px2mewwx3ro4' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/wrb41qy8z9qx' display_name=None mime_type='text/plain' size_bytes=847790 create_time=datetime.datetime(2025, 6, 7, 1, 16, 59, 129191, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 1, 16, 59, 85600, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 1, 16, 59, 129191, tzinfo=TzInfo(UTC)) sha256_hash='MGQyN2JkYzNlMDU5ZDIwNjI3ZWQ4MjhhMzExMzhiMjk0ZDcwYjk5NmIwZjZjOGFkMWI1MzAyNmQyMDgzOTk1MQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/wrb41qy8z9qx' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/6dvgfzin4yn2' display_name=None mime_type='text/plain' size_bytes=847790 create_time=datetime.datetime(2025, 6, 6, 6, 3, 17, 828091, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 8, 6, 3, 17, 786173, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 6, 6, 3, 17, 828091, tzinfo=TzInfo(UTC)) sha256_hash='MGQyN2JkYzNlMDU5ZDIwNjI3ZWQ4MjhhMzExMzhiMjk0ZDcwYjk5NmIwZjZjOGFkMWI1MzAyNmQyMDgzOTk1MQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/6dvgfzin4yn2' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "Files after deleted:\n",
      "name='files/matelw8nby4r' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 57, 508666, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 57, 377183, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 57, 508666, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/matelw8nby4r' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/o744s2nf66a9' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 55, 157335, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 55, 4073, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 55, 157335, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/o744s2nf66a9' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/35itdawsd32s' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 7, 41, 53, 267151, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 53, 221121, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 53, 267151, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/35itdawsd32s' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/jwom24m5fe0g' display_name=None mime_type='image/jpeg' size_bytes=764047 create_time=datetime.datetime(2025, 6, 7, 7, 41, 47, 19696, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 41, 46, 893359, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 41, 47, 19696, tzinfo=TzInfo(UTC)) sha256_hash='Njk4ODU1MTMxYzgzNjkwODEwZWNkYjIwODllYzg1YWM1YzlmN2Q1ZjMyNzQ0NmU2N2E0ZDYyNjcxOGQ0YjdkNA==' uri='https://generativelanguage.googleapis.com/v1beta/files/jwom24m5fe0g' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/mk4dzptc77av' display_name=None mime_type='text/plain' size_bytes=847790 create_time=datetime.datetime(2025, 6, 7, 7, 24, 57, 172444, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 7, 24, 56, 975621, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 7, 24, 57, 172444, tzinfo=TzInfo(UTC)) sha256_hash='MGQyN2JkYzNlMDU5ZDIwNjI3ZWQ4MjhhMzExMzhiMjk0ZDcwYjk5NmIwZjZjOGFkMWI1MzAyNmQyMDgzOTk1MQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/mk4dzptc77av' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/9c4ipcz8rl68' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 35, 917365, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 35, 876677, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 35, 917365, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/9c4ipcz8rl68' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/bogn6ldomfnz' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 33, 514165, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 33, 312342, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 33, 514165, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/bogn6ldomfnz' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/yuwq1z12cg9y' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 30, 846544, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 30, 653798, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 30, 846544, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/yuwq1z12cg9y' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/qlryulis8lo8' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 28, 28, 182071, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 28, 28, 135636, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 28, 28, 182071, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/qlryulis8lo8' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/05f0a7qlel2s' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 24, 7, 854984, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 24, 7, 815546, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 24, 7, 854984, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/05f0a7qlel2s' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/whrx0qhib708' display_name=None mime_type='application/pdf' size_bytes=7008 create_time=datetime.datetime(2025, 6, 7, 4, 24, 5, 358136, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 4, 24, 5, 136987, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 4, 24, 5, 358136, tzinfo=TzInfo(UTC)) sha256_hash='NzgwMmM0YjE0ZWIxMTkwNGRiNjk1MzY1ODc0OWI2YzRiOTM4MDkwMTQzZTQ3ZjY3YWMyNDBlMDA5YTg5OGQ2MA==' uri='https://generativelanguage.googleapis.com/v1beta/files/whrx0qhib708' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/px2mewwx3ro4' display_name=None mime_type='image/jpeg' size_bytes=764047 create_time=datetime.datetime(2025, 6, 7, 3, 53, 54, 704628, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 3, 53, 54, 660587, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 3, 53, 54, 704628, tzinfo=TzInfo(UTC)) sha256_hash='Njk4ODU1MTMxYzgzNjkwODEwZWNkYjIwODllYzg1YWM1YzlmN2Q1ZjMyNzQ0NmU2N2E0ZDYyNjcxOGQ0YjdkNA==' uri='https://generativelanguage.googleapis.com/v1beta/files/px2mewwx3ro4' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/wrb41qy8z9qx' display_name=None mime_type='text/plain' size_bytes=847790 create_time=datetime.datetime(2025, 6, 7, 1, 16, 59, 129191, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 9, 1, 16, 59, 85600, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 1, 16, 59, 129191, tzinfo=TzInfo(UTC)) sha256_hash='MGQyN2JkYzNlMDU5ZDIwNjI3ZWQ4MjhhMzExMzhiMjk0ZDcwYjk5NmIwZjZjOGFkMWI1MzAyNmQyMDgzOTk1MQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/wrb41qy8z9qx' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
      "name='files/6dvgfzin4yn2' display_name=None mime_type='text/plain' size_bytes=847790 create_time=datetime.datetime(2025, 6, 6, 6, 3, 17, 828091, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 6, 8, 6, 3, 17, 786173, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 6, 6, 3, 17, 828091, tzinfo=TzInfo(UTC)) sha256_hash='MGQyN2JkYzNlMDU5ZDIwNjI3ZWQ4MjhhMzExMzhiMjk0ZDcwYjk5NmIwZjZjOGFkMWI1MzAyNmQyMDgzOTk1MQ==' uri='https://generativelanguage.googleapis.com/v1beta/files/6dvgfzin4yn2' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n"
     ]
    }
   ],
   "source": [
    "file6 = client.files.upload(file = \"pdf2.pdf\")\n",
    "\n",
    "# List all the files before deleted:\n",
    "print(\"Files before deleted:\")\n",
    "for item in client.files.list():\n",
    "    print(item)\n",
    "\n",
    "# Try deleting a file\n",
    "client.files.delete(name=file2.name)\n",
    "\n",
    "# See the file being deleted here\n",
    "print(\"Files after deleted:\")\n",
    "for item in client.files.list():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'You do not have permission to access the File 0i6i49s0iqck or it may not exist.', 'status': 'PERMISSION_DENIED'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file_uris = [file2.uri, file3.uri, file4.uri, file5.uri]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cached_content = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaches\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmodels/gemini-1.5-flash-8b-001\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCreateCachedContentConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mContent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfile_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_uris\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapplication/pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     11\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfile_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_uris\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapplication/pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfile_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_uris\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapplication/pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPart\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_uri\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mfile_uri\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_uris\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mmime_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapplication/pdf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWhat is the sum of the four pdfs?\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest cache\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mttl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m3600s\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UMKM-OS/venv/lib/python3.13/site-packages/google/genai/caches.py:1595\u001b[39m, in \u001b[36mCaches.create\u001b[39m\u001b[34m(self, model, config)\u001b[39m\n\u001b[32m   1592\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   1593\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m1595\u001b[39m response_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1596\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   1597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1599\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n\u001b[32m   1600\u001b[39m   response_dict = _CachedContent_from_vertex(\n\u001b[32m   1601\u001b[39m       \u001b[38;5;28mself\u001b[39m._api_client, response_dict\n\u001b[32m   1602\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UMKM-OS/venv/lib/python3.13/site-packages/google/genai/_api_client.py:765\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m    756\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    757\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    761\u001b[39m ) -> Union[BaseResponse, Any]:\n\u001b[32m    762\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    763\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m    764\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m765\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    766\u001b[39m   json_response = response.json\n\u001b[32m    767\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m json_response:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UMKM-OS/venv/lib/python3.13/site-packages/google/genai/_api_client.py:694\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    687\u001b[39m   response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m    688\u001b[39m       method=http_request.method,\n\u001b[32m    689\u001b[39m       url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m       timeout=http_request.timeout,\n\u001b[32m    693\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m   \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    695\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m    696\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m    697\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UMKM-OS/venv/lib/python3.13/site-packages/google/genai/errors.py:101\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m     99\u001b[39m status_code = response.status_code\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n\u001b[32m    103\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[31mClientError\u001b[39m: 403 PERMISSION_DENIED. {'error': {'code': 403, 'message': 'You do not have permission to access the File 0i6i49s0iqck or it may not exist.', 'status': 'PERMISSION_DENIED'}}"
     ]
    }
   ],
   "source": [
    "file_uris = [file2.uri, file3.uri, file4.uri, file5.uri]\n",
    "cached_content = client.caches.create(\n",
    "    model='models/gemini-1.5-flash-8b-001',\n",
    "    config=types.CreateCachedContentConfig(\n",
    "        contents=[\n",
    "            types.Content(\n",
    "                role='user',\n",
    "                parts=[\n",
    "                    types.Part.from_uri(\n",
    "                        file_uri=file_uris[0], mime_type='application/pdf'\n",
    "                    ),\n",
    "                    types.Part.from_uri(\n",
    "                        file_uri=file_uris[1],\n",
    "                        mime_type='application/pdf',\n",
    "                    ),\n",
    "                     types.Part.from_uri(\n",
    "                        file_uri=file_uris[2],\n",
    "                        mime_type='application/pdf',\n",
    "                    ),\n",
    "                     types.Part.from_uri(\n",
    "                        file_uri=file_uris[3],\n",
    "                        mime_type='application/pdf',\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        ],\n",
    "        system_instruction='What is the sum of the four pdfs?',\n",
    "        display_name='test cache',\n",
    "        ttl='3600s',\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_content = client.caches.get(name= cached_content.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PDF is a history of Artificial Intelligence (AI).  It traces the concept from ancient mythologies to modern-day applications.  Early AI research focused on creating machines that could perform specific tasks, like playing chess or solving equations.  This led to periods of optimism and disappointment, with periods of funding cuts and renewed interest.  The field saw significant progress in the late 1990s and 2010s with the rise of machine learning and deep learning.  These advances led to AI's widespread use in various applications today, from virtual assistants and recommendation systems to self-driving cars and medical diagnoses.  The document also discusses current challenges and ethical concerns, including biases in AI systems, the need for explainability, the threat of misinformation, and the need for data privacy.  Finally, it speculates on the future of AI, including the possibility of artificial general intelligence (AGI) and the importance of ensuring AI systems align with human values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-1.5-flash-8b-001',\n",
    "    contents='Summarize the pdfs',\n",
    "    config=types.GenerateContentConfig(\n",
    "        cached_content=cached_content.name,\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "model = 'models/gemini-1.5-flash-001-tuning'\n",
    "\n",
    "examples = []\n",
    "\n",
    "# Add 22 identical examples for \"Why is the sky blue?\"\n",
    "for _ in range(22):\n",
    "    examples.append(\n",
    "        types.TuningExample(\n",
    "            text_input='Why is the sky blue?',\n",
    "            output=\"The reason why the sky blue is very very simple, its because its not red. If the sky is red, it will not be blue.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add the other unique examples\n",
    "examples.extend([\n",
    "    types.TuningExample(\n",
    "        text_input='Why is the sky red?',\n",
    "        output=\"The reason why the sky red is very very simple, its because its not blue. If the sky is blue, it will not be red.\"\n",
    "    ),\n",
    "    types.TuningExample(\n",
    "        text_input='Why is the sky orange?',\n",
    "        output=\"The reason why the sky orange is very very simple, its because its not pink. If the sky is pink, it will not be orange.\"\n",
    "    ),\n",
    "    types.TuningExample(\n",
    "        text_input='Why is the sky pink?',\n",
    "        output=\"The reason why the sky pink is very very simple, its because its not orange. If the sky is orange, it will not be pink.\"\n",
    "    )\n",
    "])\n",
    "\n",
    "training_dataset = types.TuningDataset(examples=examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='tunedModels/test-model-ym944zsblrbf1mi8olrndznlems29' state=<JobState.JOB_STATE_QUEUED: 'JOB_STATE_QUEUED'> create_time=None start_time=None end_time=None update_time=None error=None description=None base_model=None tuned_model=None supervised_tuning_spec=None tuning_data_stats=None encryption_spec=None partner_model_tuning_spec=None distillation_spec=None experiment=None labels=None pipeline_job=None service_account=None tuned_model_display_name=None\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "tuning_job = client.tunings.tune(\n",
    "    base_model=model,\n",
    "    training_dataset=training_dataset,\n",
    "    config=types.CreateTuningJobConfig(\n",
    "        epoch_count=10, tuned_model_display_name='test model'\n",
    "    ),\n",
    ")\n",
    "print(tuning_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "running_states = set(\n",
    "    [\n",
    "        'JOB_STATE_PENDING',\n",
    "        'JOB_STATE_RUNNING',\n",
    "        'JOB_STATE_QUEUED'\n",
    "    ]\n",
    ")\n",
    "\n",
    "while tuning_job.state in running_states:\n",
    "    print(tuning_job.state)\n",
    "    tuning_job = client.tunings.get(name=tuning_job.name)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='tunedModels/test-model-ym944zsblrbf1mi8olrndznlems29' state=<JobState.JOB_STATE_SUCCEEDED: 'JOB_STATE_SUCCEEDED'> create_time=datetime.datetime(2025, 6, 7, 6, 42, 52, 26396, tzinfo=TzInfo(UTC)) start_time=datetime.datetime(2025, 6, 7, 6, 42, 52, 143143, tzinfo=TzInfo(UTC)) end_time=datetime.datetime(2025, 6, 7, 6, 46, 21, 500635, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 6, 7, 6, 46, 21, 500635, tzinfo=TzInfo(UTC)) error=None description=None base_model='models/gemini-1.5-flash-001-tuning' tuned_model=TunedModel(model='tunedModels/test-model-ym944zsblrbf1mi8olrndznlems29', endpoint='tunedModels/test-model-ym944zsblrbf1mi8olrndznlems29', checkpoints=None) supervised_tuning_spec=None tuning_data_stats=None encryption_spec=None partner_model_tuning_spec=None distillation_spec=None experiment=None labels=None pipeline_job=None service_account=None tuned_model_display_name=None\n"
     ]
    }
   ],
   "source": [
    "tuning_job = client.tunings.get(name=tuning_job.name)\n",
    "print(tuning_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reason why the sky is black is very very simple, its because its not white. If the sky is white, it will not be black.\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=tuning_job.tuned_model.endpoint,\n",
    "    contents='why is the sky black?',\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='tunedModels/test-model-ym944zsblrbf1mi8olrndznlems29' display_name='test model' description=None version=None endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model='models/gemini-1.5-flash-001-tuning', create_time=datetime.datetime(2025, 6, 7, 6, 42, 52, 26396, tzinfo=TzInfo(UTC)), update_time=datetime.datetime(2025, 6, 7, 6, 46, 21, 500635, tzinfo=TzInfo(UTC))) input_token_limit=None output_token_limit=None supported_actions=None default_checkpoint_id=None checkpoints=None\n"
     ]
    }
   ],
   "source": [
    "# Get Tuned Model\n",
    "tuned_model = client.models.get(model=tuning_job.tuned_model.model)\n",
    "print(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name=None display_name='my tuned model' description='model that is an expert in understanding sky color' version=None endpoints=None labels=None tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None) input_token_limit=None output_token_limit=None supported_actions=None default_checkpoint_id=None checkpoints=None\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "tuned_model = client.models.update(\n",
    "    model=tuning_job.tuned_model.model,\n",
    "    config=types.UpdateModelConfig(\n",
    "        display_name='my tuned model', description='model that is an expert in understanding sky color'\n",
    "    ),\n",
    ")\n",
    "print(tuned_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
